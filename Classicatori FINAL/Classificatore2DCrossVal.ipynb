{"cells":[{"cell_type":"markdown","metadata":{},"source":["## import"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T14:41:29.243721Z","iopub.status.busy":"2024-09-12T14:41:29.243296Z","iopub.status.idle":"2024-09-12T14:41:29.260564Z","shell.execute_reply":"2024-09-12T14:41:29.259665Z","shell.execute_reply.started":"2024-09-12T14:41:29.243682Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","# Import libraries\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import ttest_ind\n","from xgboost import XGBClassifier\n","import statistics\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import balanced_accuracy_score\n","\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["## caricamento dati"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento labels pazienti"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels: [0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0\n"," 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n"," 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0\n"," 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n","Number of labels: 129\n","Patient Names:  [5, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 133, 135, 136, 137, 138, 139, 141, 142, 144, 146, 147, 149, 150, 153, 155, 158, 159, 161, 163, 166, 168, 169, 170, 171, 175, 176, 178, 182, 183, 188, 189, 190, 193, 197, 199, 200, 205]\n"]}],"source":["\n","file_path = \"../CSV/data_rad_clin_DEF.csv\"\n","\n","data = pd.read_csv(file_path)\n","labels_column = data['label']\n","labels = labels_column.astype(int).tolist()\n","\n","labels=np.array(labels)\n","\n","# Estrazione dei numeri dai nomi dei pazienti\n","loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n","\n","print(\"Labels:\", labels)\n","print(\"Number of labels:\", len(labels))\n","print(\"Patient Names: \", loaded_patients )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features encoder"]},{"cell_type":"code","execution_count":212,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.2025036  0.5720962  0.5447646  ... 1.1191139  1.1651635  0.94069195]\n"," [0.80343825 3.566265   0.6634056  ... 3.4075627  0.         0.03612597]\n"," [2.1060686  0.7906144  0.82881254 ... 0.7284154  0.39611563 1.2460136 ]\n"," ...\n"," [1.6857586  0.71615916 0.         ... 0.         0.03223638 0.38544273]\n"," [0.77305645 1.3281341  0.         ... 2.4427867  0.         0.1173447 ]\n"," [0.6291671  3.0247831  1.1139797  ... 1.9223992  0.7866627  1.2099525 ]]\n","(129, 2048)\n"]}],"source":["#file_path = \"../CSV/EncodersSliceMaggiore/VGG19_Slice_Maggiore.csv\"\n","file_path = \"../CSV/EncodersSliceMaggiore/InceptionV3_Slice_Maggiore.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","\n","\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","df_features = df_ordered.drop(columns=['Unnamed: 0'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features radiomica"]},{"cell_type":"code","execution_count":202,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[5.83888273e-01 2.49810487e+01 2.57099203e+01 ... 1.13404359e+03\n","  2.37470314e-01 7.12523395e+01]\n"," [8.68120272e-01 2.78353641e+01 2.75136330e+01 ... 2.79627909e+03\n","  1.66740377e-01 9.88514518e+01]\n"," [6.68428011e-01 3.34967625e+01 3.44818793e+01 ... 2.84190381e+02\n","  4.27515541e-02 4.71863205e+01]\n"," ...\n"," [8.95387032e-01 3.24479655e+01 2.80178515e+01 ... 6.33694339e+01\n","  1.64536668e-01 1.17728372e+01]\n"," [7.82116308e-01 2.65896102e+01 2.56320112e+01 ... 3.36424176e+03\n","  3.35445375e-01 6.76993135e+01]\n"," [5.58702485e-01 3.61138047e+01 3.58468967e+01 ... 2.19527898e+03\n","  2.01081360e-01 7.96408761e+01]]\n","(129, 102)\n"]}],"source":["file_path = \"../CSV/EncodersSliceMaggiore/Radiomica_2D.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","#df = df.astype(float)\n","\n","# Colonne da rimuovere SOLO PER RADIOMICA\n","columns_to_remove = [\n","    'Slice',\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","df_cleaned = df.drop(columns=columns_to_remove)\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)  "]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.774442Z","iopub.status.busy":"2024-09-12T14:41:29.774064Z","iopub.status.idle":"2024-09-12T14:41:29.814876Z","shell.execute_reply":"2024-09-12T14:41:29.813996Z","shell.execute_reply.started":"2024-09-12T14:41:29.774406Z"},"trusted":true},"outputs":[],"source":["\n","## Rimozione feature correlation\n","def remove_highly_correlated_features(X, threshold=0.85):\n","    corr_matrix = np.corrcoef(X, rowvar=False)\n","    upper_triangle = np.triu(corr_matrix, k=1)\n","    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n","    X_reduced = np.delete(X, to_drop, axis=1)\n","    return X_reduced, to_drop\n","\n","## Rimozione features p_value\n","def remove_high_pvalue_features(X, y, alpha=0.05):\n","    selector = SelectKBest(score_func=f_classif, k='all')\n","    selector.fit(X, y)\n","    p_values = selector.pvalues_\n","    features_to_keep = np.where(p_values < alpha)[0]\n","    X_reduced = X[:, features_to_keep]\n","    return X_reduced, features_to_keep\n","\n","## FEATURE SELECTION LASSO\n","def select_features_with_lasso(X, y, alpha=0.001):\n","    \n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X, y)\n","    coefficients = lasso.coef_\n","    selected_features = np.where(coefficients != 0)[0]\n","    X_selected = X[:, selected_features]\n","\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION LOGISTIC\n","def logistic_regression_feature_selection(X, y, num_features):\n","    lr = LogisticRegression(max_iter=2000, random_state=42)\n","    lr.fit(X, y)\n","    coef_abs = np.abs(lr.coef_)\n","    feature_importances = np.mean(coef_abs, axis=0)\n","    selected_features = feature_importances.argsort()[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION MRMR\n","def mrmr_feature_selection(X, y, num_features):\n","    mi = mutual_info_classif(X, y, random_state=42)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n","    \n","    selected_features = []\n","    selected_indices = []\n","\n","    first_feature_index = np.argmax(mi)\n","    selected_features.append(first_feature_index)\n","    selected_indices.append(first_feature_index)\n","    \n","    for _ in range(num_features - 1):\n","        max_relevance = -np.inf\n","        selected_feature_index = -1\n","        \n","        for i in range(X.shape[1]):\n","            if i in selected_indices:\n","                continue\n","            \n","            relevance = mi[i]\n","            redundancy = np.mean(distances[i, selected_indices])\n","            \n","            mrmr_score = relevance - redundancy\n","            \n","            if mrmr_score > max_relevance:\n","                max_relevance = mrmr_score\n","                selected_feature_index = i\n","        \n","        selected_features.append(selected_feature_index)\n","        selected_indices.append(selected_feature_index)\n","\n","    X_selected = X[:, selected_indices]\n","    return X_selected, selected_indices\n","\n","## FEATURE SELECTION RANDOM FOREST\n","def rf_feature_selection(X, y, num_features):\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf.fit(X, y)\n","    feature_importances = rf.feature_importances_\n","    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","\n","## FEATURE SELECTION P_VALUE\n","# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n","# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n","\n","def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n","    p_values = []\n","    num_features_total = x_train_expanded.shape[1]\n","\n","    # Calcolo dei p-value per ciascuna feature\n","    for i in range(num_features_total):\n","        feature = x_train_expanded[:, i]\n","        group_0 = feature[y_train_expanded == 0]\n","        group_1 = feature[y_train_expanded == 1]\n","        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n","        p_values.append(p_val)\n","\n","\n","    p_values = np.array(p_values)\n","\n","    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n","    sorted_indices = np.argsort(p_values)\n","    sorted_indices = sorted_indices[:num_features]\n","\n","    x_train_selected = x_train_expanded[:, sorted_indices]\n","\n","    return x_train_selected, sorted_indices\n","\n","\n","\n","## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n","def filter_patients_features(filtered_patients, selected_features):\n","    filtered_patients_selected = []\n","\n","    for patient_features in filtered_patients:\n","        # Select only the features specified in selected_features\n","        patient_features_selected = patient_features[:, selected_features]\n","        filtered_patients_selected.append(patient_features_selected)\n","\n","    return filtered_patients_selected\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["## classificazione completa che ritorna la threshold migliore per la classificazione\n","def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n","    best_f1_score = 0\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n","        thresholds=[thresholds]\n","        \n","    \n","    for threshold in thresholds:\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            \n","            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n","\n","\n","            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n","                best_f1_score = f1\n","                best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'best_threshold': threshold,\n","                    'balanced accuracy': bal_acc\n","                }\n","\n","    return best_case\n","\n","\n","#####################################################################################################################################\n","\n","### questo ritorna le il vettore di probabilità senza fare la classificazione\n","def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if (len(selected_features)==0):\n","                    return [0],0,[0]\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","#####################################################################################################################################\n","\n","\n","### classificazione effettuata con una threshold specifica\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold\n","                }\n","                \n","            if not best_case:\n","                 print(\"Attenzione caso vuoto\") \n","            return best_case\n","\n","#####################################################################################################################################\n","\n","\n","# metodo che definisce la threshold ottimale attraverso Youden's J statistic (threshold_selection= 'y')\n","# oppure attraverso la distanza euclidea dalla curva ROC (threshold_selection= 'd')\n","def classification_method_selection(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, threshold_selection, mode=\"Val\", selected_features=[0]):\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        classi=classifierinitialization(classifier, X_selected, y_train_expanded )\n","        # Training del classificatore\n","        classi.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    roc_auc = roc_auc_score(y_test, y_proba_test)\n","    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","    pr_auc = auc(recall, precision)\n","        \n","    fpr,tpr,threshold=roc_curve(y_test,y_proba_test,pos_label=1)\n","    youden_j = tpr - fpr\n","    optimal_threshold = threshold[np.argmax(youden_j)]\n","\n","    ## due modalità \n","    if threshold_selection == 'y':\n","        youden_j = tpr - fpr\n","        optimal_threshold = threshold[np.argmax(youden_j)]\n","    elif threshold_selection == 'd':\n","        distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n","        optimal_threshold = threshold[np.argmin(distances)]\n","    else:\n","        print('Threshold non valida!')\n","        return None\n","\n","    \n","    y_pred_custom_test = (y_proba_test >= optimal_threshold).astype(int)\n","\n","    accuracy = accuracy_score(y_test, y_pred_custom_test)\n","    f1 = f1_score(y_test, y_pred_custom_test)\n","    conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","\n","    best_case = {\n","        'alpha': alpha,\n","        'num_features': number_features,\n","        'selected_features': selected_features,\n","        'pr_auc': pr_auc,\n","        'roc_auc': roc_auc,\n","        'f1': f1,\n","        'accuracy': accuracy,\n","        'confusion_matrix': conf,\n","        'best_threshold': optimal_threshold,\n","        'threshold_mode': threshold_selection\n","    }\n","\n","    return best_case\n","\n","def classifierinitialization(classifier):\n","    if classifier == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif classifier == 'Logistic':\n","                            classi = LogisticRegression(random_state=42, max_iter=2000)\n","    elif classifier == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif classifier == 'XgBoost':\n","                            classi = XGBClassifier(random_state=42)\n","    elif classifier == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation = 'logistic')\n","    elif classifier == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42, max_iter=2000)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'\n","                                )\n","    return classi"]},{"cell_type":"markdown","metadata":{},"source":["## split"]},{"cell_type":"code","execution_count":213,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.977584Z","iopub.status.busy":"2024-09-12T14:41:29.977021Z","iopub.status.idle":"2024-09-12T14:41:29.982827Z","shell.execute_reply":"2024-09-12T14:41:29.981953Z","shell.execute_reply.started":"2024-09-12T14:41:29.977546Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of train patients:  90\n","Number of test patients:  39\n","Number of features for every image:  2048\n"]}],"source":["Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False)\n","\n","\n","print(\"Number of train patients: \", len(X_train))\n","print(\"Number of test patients: \", len(y_test))\n","\n","print(\"Number of features for every image: \", X_train[0].shape[0] )\n"]},{"cell_type":"markdown","metadata":{},"source":["## correlation e p_value"]},{"cell_type":"code","execution_count":214,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.617818Z","iopub.status.busy":"2024-09-12T14:41:30.616974Z","iopub.status.idle":"2024-09-12T14:41:30.650271Z","shell.execute_reply":"2024-09-12T14:41:30.649099Z","shell.execute_reply.started":"2024-09-12T14:41:30.617778Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(90, 1844)\n","(39, 1844)\n","(90, 96)\n","(39, 96)\n"]}],"source":["\n","## FEATURE CORRELATION\n","\n","X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.8)\n","X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n","\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n","\n","# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n","\n","X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, Y_train, alpha=0.01)\n","X_test_reduced = X_test_reduced[:, features_to_keep]\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## parametri"]},{"cell_type":"code","execution_count":221,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.820390Z","iopub.status.busy":"2024-09-12T14:41:30.820019Z","iopub.status.idle":"2024-09-12T14:41:30.825775Z","shell.execute_reply":"2024-09-12T14:41:30.824852Z","shell.execute_reply.started":"2024-09-12T14:41:30.820355Z"},"trusted":true},"outputs":[],"source":["\n","\n","alpha_1 = np.linspace(0.01, 0.6, 30).tolist() ## RANGE PER RESNET\n","\n","#alpha_1 = np.linspace(0.005, 0.5, 30).tolist() ## RANGE PER VGG\n","\n","#alpha_2 = np.linspace(0, 0.005, 21).tolist()\n","\n","alpha_values=alpha_1 \n","#alpha_values.remove(0.0)\n","\n","\n","#thresholds=np.arange(0.4, 0.61, 0.01) \n","\n","thresholds=[0.5]\n","\n","#selectors=['lasso', 'mrmr','rf', 'logistic']\n","\n","#classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n","classifiers=['SVM', 'ensemble','RandomForest', 'Logistic']\n","selectors=['mrmr','rf', 'logistic', 'lasso']\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loop per Validation"]},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[],"source":["\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'selected_features': [],\n","                'balanced accuracy': None\n","            }\n","\n","\n","results_val_others = [template_dict.copy() for _ in range(5000)]\n","results_val_others.append(template_dict.copy())\n","\n","results_val_lasso = [template_dict.copy() for _ in range(5000)]\n","results_val_lasso.append(template_dict.copy())\n","\n","results_test_others = [template_dict.copy() for _ in range(5000)]\n","results_test_others.append(template_dict.copy())\n","\n","results_test_lasso = [template_dict.copy() for _ in range(5000)]\n","results_test_lasso.append(template_dict.copy())\n","\n","\n","smote = SMOTE(random_state=42)\n"," \n","k=0\n","u=0\n","n_folds=5\n","\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting with fold: 0\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 1\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 2\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 3\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 4\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n"]}],"source":["for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n","\n","    #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n","\n","\n","    for i, classifier in enumerate(classifiers):\n","            print(\"Starting with classifier:\", classifier)\n","            for j, selector in enumerate(selectors):\n","                print(\"Starting with selector:\", selector)\n","\n","                if(selector=='lasso'):\n","\n","                    for alpha in alpha_values:\n","                        #print(\"Doing alpha \", alpha )\n","                        classi= classifierinitialization(classifier)\n","                        best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                        \n","                        if(best_case_val==0):\n","                            continue\n","                        \n","                        results_val_lasso[k] = {\n","                                            'fold': fold_idx,\n","                                            'classifier': classifier,\n","                                            'selector': selector,\n","                                            'alpha': alpha,\n","                                            'num_features': best_case_val['num_features'],\n","                                            'selected_features': best_case_val['selected_features'],\n","                                            'pr_auc': best_case_val['pr_auc'],\n","                                            'roc_auc': best_case_val['roc_auc'],\n","                                            'f1': best_case_val['f1'],\n","                                            'accuracy': best_case_val['accuracy'],\n","                                            'confusion_matrix': best_case_val['confusion_matrix'],\n","                                            'balanced accuracy': best_case_val['balanced accuracy'],\n","                                            }\n","\n","                        #print(best_case_val['num_features'])\n","                        \n","\n","                        if(fold_idx==0):\n","                            classi= classifierinitialization(classifier)\n","                            best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","                            if(best_case_test==0):\n","                                continue\n","                            results_test_lasso[u] = {\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': alpha,\n","                                                'num_features': best_case_test['num_features'],\n","                                                'selected_features': best_case_test['selected_features'],\n","                                                'pr_auc': best_case_test['pr_auc'],\n","                                                'roc_auc': best_case_test['roc_auc'],\n","                                                'f1': best_case_test['f1'],\n","                                                'accuracy': best_case_test['accuracy'],\n","                                                'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                }\n","                            u=u+1\n","                        k = k + 1\n","\n","                else:\n","                    #limit=len(x_train_reduced[0]) + 1\n","                    limit=30\n","                    for t in range(1, limit):\n","                            classi= classifierinitialization(classifier)\n","\n","                            best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                    \n","                                \n","                            results_val_others[k] = {\n","                                                'fold': fold_idx,\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': 0,\n","                                                'num_features': t,\n","                                                'selected_features': best_case_val['selected_features'],\n","                                                'pr_auc': best_case_val['pr_auc'],\n","                                                'roc_auc': best_case_val['roc_auc'],\n","                                                'f1': best_case_val['f1'],\n","                                                'accuracy': best_case_val['accuracy'],\n","                                                'confusion_matrix': best_case_val['confusion_matrix'],\n","                                                'balanced accuracy': best_case_val['balanced accuracy'],\n","                                                }\n","                            #print(results_val_others[k]['f1'])\n","\n","                            if(fold_idx==0):\n","                                classi= classifierinitialization(classifier)\n","                                best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                                \n","                                results_test_others[u] = {\n","                                                    'classifier': classifier,\n","                                                    'selector': selector,\n","                                                    'alpha': 0,\n","                                                    'num_features': t,\n","                                                    'selected_features': best_case_test['selected_features'],\n","                                                    'pr_auc': best_case_test['pr_auc'],\n","                                                    'roc_auc': best_case_test['roc_auc'],\n","                                                    'f1': best_case_test['f1'],\n","                                                    'accuracy': best_case_test['accuracy'],\n","                                                    'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                    'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                    }\n","                                u=u+1\n","\n","                            k = k + 1"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Filtered results_test: 100 entries remaining\n","Filtered results_test: 516 entries remaining\n","Filtered results_test: 348 entries remaining\n","Filtered results_test: 1740 entries remaining\n"]}],"source":["# Remove all entries from results_test where 'classifier' is None\n","results_test_lasso = [entry for entry in results_test_lasso if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_test_lasso)} entries remaining\")\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_val_lasso= [entry for entry in results_val_lasso if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_val_lasso)} entries remaining\")\n","\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_test_others = [entry for entry in results_test_others if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_test_others)} entries remaining\")\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_val_others = [entry for entry in results_val_others if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_val_others)} entries remaining\")"]},{"cell_type":"markdown","metadata":{},"source":["### sorting per val"]},{"cell_type":"code","execution_count":225,"metadata":{},"outputs":[],"source":["num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","#num_features_range = list(range(1, 30))\n","\n","grid_results_others = {}\n","grid_results_lasso = {}\n","\n","selectors = ['mrmr', 'rf', 'logistic']\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            #print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                    \n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val_others:\n","                        ## qui filtro per num_features\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_others[(classifier, selector, num_features)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","\n","## ORA PER LASSO\n","selectors = ['lasso']\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        #print(f\"Sto iniziando selector {selector}\")\n","        for alpha in alpha_values:\n","                filtered_results = []\n","                for res in results_val_lasso:\n","                    ## qui filtro per alpha\n","                    if (res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha):\n","                        filtered_results.append(res)\n","\n","                if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_lasso[(classifier, selector, alpha)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']),reverse=True)\n","sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n","\n","#sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']),reverse=True)\n","#sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","# Combina i risultati di entrambi i grid search\n","sorted_results = sorted_results_others + sorted_results_lasso\n","\n","sorted_results = sorted(sorted_results, key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n","#sorted_results = sorted(sorted_results, key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### mostro migliori combo"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Migliori 10 combinazioni di parametri:\n","\n","#1:\n","Classifier: SVM\n","Selector: lasso\n","Alpha: 0.13206896551724137\n","Performance medie sul val set: \n","ROC AUC = 0.7980864197530864 (std = 0.09793381802135045), Balanced Accuracy = 0.7419444444444445 (std = 0.04413302352470422)\n","Metrics on the TEST set:\n","Selected Features: [12 16 20 27 40 41 45 51 58 68 76 95]\n","ROC AUC: 0.5493827160493827\n","F1 Score: 0.36363636363636365\n","Accuracy: 0.46153846153846156\n","Balanced Accuracy: 0.4722222222222222\n","Confusion Matrix: \n","[[12 15]\n"," [ 6  6]]\n","\n","#2:\n","Classifier: ensemble\n","Selector: lasso\n","Alpha: 0.19310344827586207\n","Performance medie sul val set: \n","ROC AUC = 0.74320987654321 (std = 0.0672859857830162), Balanced Accuracy = 0.7369444444444445 (std = 0.06075178450866817)\n","Metrics on the TEST set:\n","Selected Features: [16 20 35 40 45 58 68 76 95]\n","ROC AUC: 0.5030864197530864\n","F1 Score: 0.4666666666666667\n","Accuracy: 0.5897435897435898\n","Balanced Accuracy: 0.587962962962963\n","Confusion Matrix: \n","[[16 11]\n"," [ 5  7]]\n","\n","#3:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.11172413793103447\n","Performance medie sul val set: \n","ROC AUC = 0.7693364197530863 (std = 0.08768049459253793), Balanced Accuracy = 0.7355555555555555 (std = 0.09275760758790678)\n","Metrics on the TEST set:\n","Selected Features: [ 9 12 16 20 27 40 41 45 51 58 68 76 95]\n","ROC AUC: 0.4089506172839506\n","F1 Score: 0.14285714285714285\n","Accuracy: 0.38461538461538464\n","Balanced Accuracy: 0.32407407407407407\n","Confusion Matrix: \n","[[13 14]\n"," [10  2]]\n","\n","#4:\n","Classifier: SVM\n","Selector: lasso\n","Alpha: 0.01\n","Performance medie sul val set: \n","ROC AUC = 0.7731172839506172 (std = 0.09311448853511592), Balanced Accuracy = 0.7333333333333333 (std = 0.08960755486502735)\n","Metrics on the TEST set:\n","Selected Features: [ 0  1  3  4  9 10 11 12 15 16 20 22 23 25 26 27 29 30 31 33 34 35 38 39\n"," 41 44 45 46 49 51 52 55 58 59 61 63 66 68 70 71 72 73 76 77 78 79 80 86\n"," 87 89 90 91 92 94 95]\n","ROC AUC: 0.5771604938271604\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Balanced Accuracy: 0.5046296296296297\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#5:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.17275862068965517\n","Performance medie sul val set: \n","ROC AUC = 0.8003858024691357 (std = 0.08258501748372811), Balanced Accuracy = 0.7291666666666666 (std = 0.09176131477310513)\n","Metrics on the TEST set:\n","Selected Features: [16 20 35 40 45 58 68 76 95]\n","ROC AUC: 0.4830246913580247\n","F1 Score: 0.42424242424242425\n","Accuracy: 0.5128205128205128\n","Balanced Accuracy: 0.5324074074074074\n","Confusion Matrix: \n","[[13 14]\n"," [ 5  7]]\n","\n","#6:\n","Classifier: RandomForest\n","Selector: logistic\n","Num_features: 28\n","Performance medie sul val set: \n","ROC AUC = 0.7394907407407408 (std = 0.061692659409087795), Balanced Accuracy = 0.7244444444444444 (std = 0.10644091417249545)\n","Metrics on the TEST set:\n","Selected Features: [ 1 12 89 41  9 66 20 29 38 76 61 14 51 90 73  0 45 91 55 39 70 34 10  3\n"," 37 65 95 94]\n","ROC AUC: 0.5277777777777778\n","F1 Score: 0.38461538461538464\n","Accuracy: 0.5897435897435898\n","Balanced Accuracy: 0.5416666666666666\n","Confusion Matrix: \n","[[18  9]\n"," [ 7  5]]\n","\n","#7:\n","Classifier: RandomForest\n","Selector: logistic\n","Num_features: 17\n","Performance medie sul val set: \n","ROC AUC = 0.7594444444444445 (std = 0.0543368941971075), Balanced Accuracy = 0.7233333333333333 (std = 0.062402702042637724)\n","Metrics on the TEST set:\n","Selected Features: [ 1 12 89 41  9 66 20 29 38 76 61 14 51 90 73  0 45]\n","ROC AUC: 0.5200617283950617\n","F1 Score: 0.23076923076923078\n","Accuracy: 0.48717948717948717\n","Balanced Accuracy: 0.4212962962962963\n","Confusion Matrix: \n","[[16 11]\n"," [ 9  3]]\n","\n","#8:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.13206896551724137\n","Performance medie sul val set: \n","ROC AUC = 0.7930709876543209 (std = 0.11987523302388878), Balanced Accuracy = 0.7208333333333333 (std = 0.12658714609136096)\n","Metrics on the TEST set:\n","Selected Features: [12 16 20 27 40 41 45 51 58 68 76 95]\n","ROC AUC: 0.49382716049382713\n","F1 Score: 0.3333333333333333\n","Accuracy: 0.48717948717948717\n","Balanced Accuracy: 0.46759259259259256\n","Confusion Matrix: \n","[[14 13]\n"," [ 7  5]]\n","\n","#9:\n","Classifier: SVM\n","Selector: lasso\n","Alpha: 0.030344827586206893\n","Performance medie sul val set: \n","ROC AUC = 0.7506481481481482 (std = 0.08828559254193237), Balanced Accuracy = 0.7180555555555557 (std = 0.0676860718389511)\n","Metrics on the TEST set:\n","Selected Features: [ 0  1  9 10 11 12 15 18 20 29 31 37 39 40 41 44 45 46 51 55 58 59 63 66\n"," 68 72 75 76 81 87 89 90 91 92]\n","ROC AUC: 0.529320987654321\n","F1 Score: 0.4117647058823529\n","Accuracy: 0.48717948717948717\n","Balanced Accuracy: 0.5138888888888888\n","Confusion Matrix: \n","[[12 15]\n"," [ 5  7]]\n","\n","#10:\n","Classifier: SVM\n","Selector: lasso\n","Alpha: 0.19310344827586207\n","Performance medie sul val set: \n","ROC AUC = 0.7282716049382716 (std = 0.03997113179629348), Balanced Accuracy = 0.7144444444444444 (std = 0.07868150558414382)\n","Metrics on the TEST set:\n","Selected Features: [16 20 35 40 45 58 68 76 95]\n","ROC AUC: 0.4783950617283951\n","F1 Score: 0.42424242424242425\n","Accuracy: 0.5128205128205128\n","Balanced Accuracy: 0.5324074074074074\n","Confusion Matrix: \n","[[13 14]\n"," [ 5  7]]\n"]}],"source":["n=10\n","best_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_combinations, start=1):\n","\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","        print(f\"Alpha: {params[2]}\")\n","    else:\n","        print(f\"Num_features: {params[2]}\")\n","\n","    print(f\"Performance medie sul val set: \\nROC AUC = {metrics['avg_roc_auc']} (std = {metrics['std_roc_auc']}), \"f\"Balanced Accuracy = {metrics['avg_balaccuracy']} (std = {metrics['std_balaccuracy']})\")\n","\n","\n","\n","    for p in range (0, len(results_test_others)):\n","            if(params[1]=='lasso'):\n","                if(results_test_lasso[p]['classifier']==params[0] and results_test_lasso[p]['alpha']==params[2]):\n","                        best_case=results_test_lasso[p]\n","                        break\n","            else:     \n","                if(results_test_others[p]['classifier']==params[0] and results_test_others[p]['selector']==params[1] and results_test_others[p]['num_features']==params[2]):\n","                        best_case=results_test_others[p]\n","                        break\n","\n","    \n","    print(\"Metrics on the TEST set:\")\n","\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5686764,"sourceId":9375373,"sourceType":"datasetVersion"},{"datasetId":5686788,"sourceId":9375404,"sourceType":"datasetVersion"},{"datasetId":5687116,"sourceId":9375826,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
