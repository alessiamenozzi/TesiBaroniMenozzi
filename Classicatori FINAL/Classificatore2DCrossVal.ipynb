{"cells":[{"cell_type":"markdown","metadata":{},"source":["## import"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T14:41:29.243721Z","iopub.status.busy":"2024-09-12T14:41:29.243296Z","iopub.status.idle":"2024-09-12T14:41:29.260564Z","shell.execute_reply":"2024-09-12T14:41:29.259665Z","shell.execute_reply.started":"2024-09-12T14:41:29.243682Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","# Import libraries\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import ttest_ind\n","from xgboost import XGBClassifier\n","import statistics\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import balanced_accuracy_score\n","\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["## caricamento dati"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento labels pazienti"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels: [0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0\n"," 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n"," 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0\n"," 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n","Number of labels: 129\n","Patient Names:  [5, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 133, 135, 136, 137, 138, 139, 141, 142, 144, 146, 147, 149, 150, 153, 155, 158, 159, 161, 163, 166, 168, 169, 170, 171, 175, 176, 178, 182, 183, 188, 189, 190, 193, 197, 199, 200, 205]\n"]}],"source":["\n","file_path = \"../CSV/data_rad_clin_DEF.csv\"\n","\n","data = pd.read_csv(file_path)\n","labels_column = data['label']\n","labels = labels_column.astype(int).tolist()\n","\n","labels=np.array(labels)\n","\n","# Estrazione dei numeri dai nomi dei pazienti\n","loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n","\n","print(\"Labels:\", labels)\n","print(\"Number of labels:\", len(labels))\n","print(\"Patient Names: \", loaded_patients )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features encoder"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 10.644694  42.666046   0.       ...   0.        18.299337   6.166822]\n"," [  0.       102.23023    0.       ...  18.42938   31.46421    0.      ]\n"," [  0.946728  28.357668   0.       ...   0.        18.290043   9.094667]\n"," ...\n"," [ 11.950816  10.536694  14.736543 ...   0.        27.75255   13.213755]\n"," [  0.       161.865      0.       ...   0.        19.546183  16.224407]\n"," [  0.       129.88449    0.       ...   0.        48.395874  11.344899]]\n","(129, 512)\n"]}],"source":["file_path = \"../CSV/EncodersSliceMaggiore/VGG19_Slice_Maggiore.csv\"\n","#file_path = \"../CSV/EncodersSliceMaggiore/InceptionV3_Slice_Maggiore.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","\n","\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","df_features = df_ordered.drop(columns=['Unnamed: 0'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features radiomica"]},{"cell_type":"code","execution_count":202,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[5.83888273e-01 2.49810487e+01 2.57099203e+01 ... 1.13404359e+03\n","  2.37470314e-01 7.12523395e+01]\n"," [8.68120272e-01 2.78353641e+01 2.75136330e+01 ... 2.79627909e+03\n","  1.66740377e-01 9.88514518e+01]\n"," [6.68428011e-01 3.34967625e+01 3.44818793e+01 ... 2.84190381e+02\n","  4.27515541e-02 4.71863205e+01]\n"," ...\n"," [8.95387032e-01 3.24479655e+01 2.80178515e+01 ... 6.33694339e+01\n","  1.64536668e-01 1.17728372e+01]\n"," [7.82116308e-01 2.65896102e+01 2.56320112e+01 ... 3.36424176e+03\n","  3.35445375e-01 6.76993135e+01]\n"," [5.58702485e-01 3.61138047e+01 3.58468967e+01 ... 2.19527898e+03\n","  2.01081360e-01 7.96408761e+01]]\n","(129, 102)\n"]}],"source":["file_path = \"../CSV/EncodersSliceMaggiore/Radiomica_2D.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","#df = df.astype(float)\n","\n","# Colonne da rimuovere SOLO PER RADIOMICA\n","columns_to_remove = [\n","    'Slice',\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","df_cleaned = df.drop(columns=columns_to_remove)\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)  "]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.774442Z","iopub.status.busy":"2024-09-12T14:41:29.774064Z","iopub.status.idle":"2024-09-12T14:41:29.814876Z","shell.execute_reply":"2024-09-12T14:41:29.813996Z","shell.execute_reply.started":"2024-09-12T14:41:29.774406Z"},"trusted":true},"outputs":[],"source":["\n","## Rimozione feature correlation\n","def remove_highly_correlated_features(X, threshold=0.85):\n","    corr_matrix = np.corrcoef(X, rowvar=False)\n","    upper_triangle = np.triu(corr_matrix, k=1)\n","    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n","    X_reduced = np.delete(X, to_drop, axis=1)\n","    return X_reduced, to_drop\n","\n","## Rimozione features p_value\n","def remove_high_pvalue_features(X, y, alpha=0.05):\n","    selector = SelectKBest(score_func=f_classif, k='all')\n","    selector.fit(X, y)\n","    p_values = selector.pvalues_\n","    features_to_keep = np.where(p_values < alpha)[0]\n","    X_reduced = X[:, features_to_keep]\n","    return X_reduced, features_to_keep\n","\n","## FEATURE SELECTION LASSO\n","def select_features_with_lasso(X, y, alpha=0.001):\n","    \n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X, y)\n","    coefficients = lasso.coef_\n","    selected_features = np.where(coefficients != 0)[0]\n","    X_selected = X[:, selected_features]\n","\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION LOGISTIC\n","def logistic_regression_feature_selection(X, y, num_features):\n","    lr = LogisticRegression(max_iter=2000, random_state=42)\n","    lr.fit(X, y)\n","    coef_abs = np.abs(lr.coef_)\n","    feature_importances = np.mean(coef_abs, axis=0)\n","    selected_features = feature_importances.argsort()[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION MRMR\n","def mrmr_feature_selection(X, y, num_features):\n","    mi = mutual_info_classif(X, y, random_state=42)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n","    \n","    selected_features = []\n","    selected_indices = []\n","\n","    first_feature_index = np.argmax(mi)\n","    selected_features.append(first_feature_index)\n","    selected_indices.append(first_feature_index)\n","    \n","    for _ in range(num_features - 1):\n","        max_relevance = -np.inf\n","        selected_feature_index = -1\n","        \n","        for i in range(X.shape[1]):\n","            if i in selected_indices:\n","                continue\n","            \n","            relevance = mi[i]\n","            redundancy = np.mean(distances[i, selected_indices])\n","            \n","            mrmr_score = relevance - redundancy\n","            \n","            if mrmr_score > max_relevance:\n","                max_relevance = mrmr_score\n","                selected_feature_index = i\n","        \n","        selected_features.append(selected_feature_index)\n","        selected_indices.append(selected_feature_index)\n","\n","    X_selected = X[:, selected_indices]\n","    return X_selected, selected_indices\n","\n","## FEATURE SELECTION RANDOM FOREST\n","def rf_feature_selection(X, y, num_features):\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf.fit(X, y)\n","    feature_importances = rf.feature_importances_\n","    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","\n","## FEATURE SELECTION P_VALUE\n","# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n","# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n","\n","def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n","    p_values = []\n","    num_features_total = x_train_expanded.shape[1]\n","\n","    # Calcolo dei p-value per ciascuna feature\n","    for i in range(num_features_total):\n","        feature = x_train_expanded[:, i]\n","        group_0 = feature[y_train_expanded == 0]\n","        group_1 = feature[y_train_expanded == 1]\n","        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n","        p_values.append(p_val)\n","\n","\n","    p_values = np.array(p_values)\n","\n","    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n","    sorted_indices = np.argsort(p_values)\n","    sorted_indices = sorted_indices[:num_features]\n","\n","    x_train_selected = x_train_expanded[:, sorted_indices]\n","\n","    return x_train_selected, sorted_indices\n","\n","\n","\n","## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n","def filter_patients_features(filtered_patients, selected_features):\n","    filtered_patients_selected = []\n","\n","    for patient_features in filtered_patients:\n","        # Select only the features specified in selected_features\n","        patient_features_selected = patient_features[:, selected_features]\n","        filtered_patients_selected.append(patient_features_selected)\n","\n","    return filtered_patients_selected\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["## classificazione completa che ritorna la threshold migliore per la classificazione\n","def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n","    best_f1_score = 0\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n","        thresholds=[thresholds]\n","        \n","    \n","    for threshold in thresholds:\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            \n","            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n","\n","\n","            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n","                best_f1_score = f1\n","                best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'best_threshold': threshold,\n","                    'balanced accuracy': bal_acc\n","                }\n","\n","    return best_case\n","\n","\n","#####################################################################################################################################\n","\n","### questo ritorna le il vettore di probabilità senza fare la classificazione\n","def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if (len(selected_features)==0):\n","                    return [0],0,[0]\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","#####################################################################################################################################\n","\n","\n","### classificazione effettuata con una threshold specifica\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold\n","                }\n","                \n","            if not best_case:\n","                 print(\"Attenzione caso vuoto\") \n","            return best_case\n","\n","#####################################################################################################################################\n","\n","\n","# metodo che definisce la threshold ottimale attraverso Youden's J statistic (threshold_selection= 'y')\n","# oppure attraverso la distanza euclidea dalla curva ROC (threshold_selection= 'd')\n","def classification_method_selection(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, threshold_selection, mode=\"Val\", selected_features=[0]):\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        classi=classifierinitialization(classifier, X_selected, y_train_expanded )\n","        # Training del classificatore\n","        classi.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    roc_auc = roc_auc_score(y_test, y_proba_test)\n","    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","    pr_auc = auc(recall, precision)\n","        \n","    fpr,tpr,threshold=roc_curve(y_test,y_proba_test,pos_label=1)\n","    youden_j = tpr - fpr\n","    optimal_threshold = threshold[np.argmax(youden_j)]\n","\n","    ## due modalità \n","    if threshold_selection == 'y':\n","        youden_j = tpr - fpr\n","        optimal_threshold = threshold[np.argmax(youden_j)]\n","    elif threshold_selection == 'd':\n","        distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n","        optimal_threshold = threshold[np.argmin(distances)]\n","    else:\n","        print('Threshold non valida!')\n","        return None\n","\n","    \n","    y_pred_custom_test = (y_proba_test >= optimal_threshold).astype(int)\n","\n","    accuracy = accuracy_score(y_test, y_pred_custom_test)\n","    f1 = f1_score(y_test, y_pred_custom_test)\n","    conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","\n","    best_case = {\n","        'alpha': alpha,\n","        'num_features': number_features,\n","        'selected_features': selected_features,\n","        'pr_auc': pr_auc,\n","        'roc_auc': roc_auc,\n","        'f1': f1,\n","        'accuracy': accuracy,\n","        'confusion_matrix': conf,\n","        'best_threshold': optimal_threshold,\n","        'threshold_mode': threshold_selection\n","    }\n","\n","    return best_case\n","\n","def classifierinitialization(classifier):\n","    if classifier == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif classifier == 'Logistic':\n","                            classi = LogisticRegression(random_state=42, max_iter=2000)\n","    elif classifier == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif classifier == 'XgBoost':\n","                            classi = XGBClassifier(random_state=42)\n","    elif classifier == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation = 'logistic')\n","    elif classifier == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42, max_iter=2000)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'\n","                                )\n","    return classi"]},{"cell_type":"markdown","metadata":{},"source":["## split"]},{"cell_type":"code","execution_count":279,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.977584Z","iopub.status.busy":"2024-09-12T14:41:29.977021Z","iopub.status.idle":"2024-09-12T14:41:29.982827Z","shell.execute_reply":"2024-09-12T14:41:29.981953Z","shell.execute_reply.started":"2024-09-12T14:41:29.977546Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of train patients:  90\n","Number of test patients:  39\n","Number of features for every image:  512\n"]}],"source":["Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False)\n","\n","\n","print(\"Number of train patients: \", len(X_train))\n","print(\"Number of test patients: \", len(y_test))\n","\n","print(\"Number of features for every image: \", X_train[0].shape[0] )\n"]},{"cell_type":"markdown","metadata":{},"source":["## correlation e p_value"]},{"cell_type":"code","execution_count":280,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.617818Z","iopub.status.busy":"2024-09-12T14:41:30.616974Z","iopub.status.idle":"2024-09-12T14:41:30.650271Z","shell.execute_reply":"2024-09-12T14:41:30.649099Z","shell.execute_reply.started":"2024-09-12T14:41:30.617778Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(90, 491)\n","(39, 491)\n","(90, 42)\n","(39, 42)\n"]}],"source":["\n","## FEATURE CORRELATION\n","\n","X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.8)\n","X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n","\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n","\n","# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n","\n","X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, Y_train, alpha=0.01)\n","X_test_reduced = X_test_reduced[:, features_to_keep]\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## parametri"]},{"cell_type":"code","execution_count":281,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.820390Z","iopub.status.busy":"2024-09-12T14:41:30.820019Z","iopub.status.idle":"2024-09-12T14:41:30.825775Z","shell.execute_reply":"2024-09-12T14:41:30.824852Z","shell.execute_reply.started":"2024-09-12T14:41:30.820355Z"},"trusted":true},"outputs":[],"source":["\n","\n","#alpha_1 = np.linspace(0.01, 0.6, 30).tolist() ## RANGE PER RESNET\n","\n","alpha_1 = np.linspace(0.005, 0.5, 30).tolist() ## RANGE PER VGG\n","\n","#alpha_2 = np.linspace(0, 0.005, 21).tolist()\n","\n","alpha_values=alpha_1 \n","#alpha_values.remove(0.0)\n","\n","\n","#thresholds=np.arange(0.4, 0.61, 0.01) \n","\n","thresholds=[0.5]\n","\n","#selectors=['lasso', 'mrmr','rf', 'logistic']\n","\n","#classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n","classifiers=['SVM', 'ensemble','RandomForest', 'Logistic']\n","selectors=['mrmr','rf', 'logistic', 'lasso']\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loop per Validation"]},{"cell_type":"code","execution_count":282,"metadata":{},"outputs":[],"source":["\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'selected_features': [],\n","                'balanced accuracy': None\n","            }\n","\n","\n","results_val_others = [template_dict.copy() for _ in range(5000)]\n","results_val_others.append(template_dict.copy())\n","\n","results_val_lasso = [template_dict.copy() for _ in range(5000)]\n","results_val_lasso.append(template_dict.copy())\n","\n","results_test_others = [template_dict.copy() for _ in range(5000)]\n","results_test_others.append(template_dict.copy())\n","\n","results_test_lasso = [template_dict.copy() for _ in range(5000)]\n","results_test_lasso.append(template_dict.copy())\n","\n","\n","smote = SMOTE(random_state=1)\n"," \n","k=0\n","u=0\n","n_folds=5\n","\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)\n"]},{"cell_type":"code","execution_count":283,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting with fold: 0\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 1\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 2\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 3\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 4\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n"]}],"source":["for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n","\n","    #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n","\n","\n","    for i, classifier in enumerate(classifiers):\n","            print(\"Starting with classifier:\", classifier)\n","            for j, selector in enumerate(selectors):\n","                print(\"Starting with selector:\", selector)\n","\n","                if(selector=='lasso'):\n","\n","                    for alpha in alpha_values:\n","                        #print(\"Doing alpha \", alpha )\n","                        classi= classifierinitialization(classifier)\n","                        best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                        \n","                        if(best_case_val==0):\n","                            continue\n","                        \n","                        results_val_lasso[k] = {\n","                                            'fold': fold_idx,\n","                                            'classifier': classifier,\n","                                            'selector': selector,\n","                                            'alpha': alpha,\n","                                            'num_features': best_case_val['num_features'],\n","                                            'selected_features': best_case_val['selected_features'],\n","                                            'pr_auc': best_case_val['pr_auc'],\n","                                            'roc_auc': best_case_val['roc_auc'],\n","                                            'f1': best_case_val['f1'],\n","                                            'accuracy': best_case_val['accuracy'],\n","                                            'confusion_matrix': best_case_val['confusion_matrix'],\n","                                            'balanced accuracy': best_case_val['balanced accuracy'],\n","                                            }\n","\n","                        #print(best_case_val['num_features'])\n","                        \n","\n","                        if(fold_idx==0):\n","                            classi= classifierinitialization(classifier)\n","                            best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","                            if(best_case_test==0):\n","                                continue\n","                            results_test_lasso[u] = {\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': alpha,\n","                                                'num_features': best_case_test['num_features'],\n","                                                'selected_features': best_case_test['selected_features'],\n","                                                'pr_auc': best_case_test['pr_auc'],\n","                                                'roc_auc': best_case_test['roc_auc'],\n","                                                'f1': best_case_test['f1'],\n","                                                'accuracy': best_case_test['accuracy'],\n","                                                'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                }\n","                            u=u+1\n","                        k = k + 1\n","\n","                else:\n","                    #limit=len(x_train_reduced[0]) + 1\n","                    limit=30\n","                    for t in range(1, limit):\n","                            classi= classifierinitialization(classifier)\n","\n","                            best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                    \n","                                \n","                            results_val_others[k] = {\n","                                                'fold': fold_idx,\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': 0,\n","                                                'num_features': t,\n","                                                'selected_features': best_case_val['selected_features'],\n","                                                'pr_auc': best_case_val['pr_auc'],\n","                                                'roc_auc': best_case_val['roc_auc'],\n","                                                'f1': best_case_val['f1'],\n","                                                'accuracy': best_case_val['accuracy'],\n","                                                'confusion_matrix': best_case_val['confusion_matrix'],\n","                                                'balanced accuracy': best_case_val['balanced accuracy'],\n","                                                }\n","                            #print(results_val_others[k]['f1'])\n","\n","                            if(fold_idx==0):\n","                                classi= classifierinitialization(classifier)\n","                                best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                                \n","                                results_test_others[u] = {\n","                                                    'classifier': classifier,\n","                                                    'selector': selector,\n","                                                    'alpha': 0,\n","                                                    'num_features': t,\n","                                                    'selected_features': best_case_test['selected_features'],\n","                                                    'pr_auc': best_case_test['pr_auc'],\n","                                                    'roc_auc': best_case_test['roc_auc'],\n","                                                    'f1': best_case_test['f1'],\n","                                                    'accuracy': best_case_test['accuracy'],\n","                                                    'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                    'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                    }\n","                                u=u+1\n","\n","                            k = k + 1"]},{"cell_type":"code","execution_count":284,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Filtered results_test: 120 entries remaining\n","Filtered results_test: 600 entries remaining\n","Filtered results_test: 348 entries remaining\n","Filtered results_test: 1740 entries remaining\n"]}],"source":["# Remove all entries from results_test where 'classifier' is None\n","results_test_lasso = [entry for entry in results_test_lasso if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_test_lasso)} entries remaining\")\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_val_lasso= [entry for entry in results_val_lasso if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_val_lasso)} entries remaining\")\n","\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_test_others = [entry for entry in results_test_others if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_test_others)} entries remaining\")\n","\n","# Remove all entries from results_test where 'classifier' is None\n","results_val_others = [entry for entry in results_val_others if entry['classifier'] is not None]\n","\n","# Print the cleaned results_test to verify\n","print(f\"Filtered results_test: {len(results_val_others)} entries remaining\")"]},{"cell_type":"markdown","metadata":{},"source":["### sorting per val"]},{"cell_type":"code","execution_count":285,"metadata":{},"outputs":[],"source":["num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","#num_features_range = list(range(1, 30))\n","\n","grid_results_others = {}\n","grid_results_lasso = {}\n","\n","selectors = ['mrmr', 'rf', 'logistic']\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            #print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                    \n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val_others:\n","                        ## qui filtro per num_features\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_others[(classifier, selector, num_features)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","\n","## ORA PER LASSO\n","selectors = ['lasso']\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        #print(f\"Sto iniziando selector {selector}\")\n","        for alpha in alpha_values:\n","                filtered_results = []\n","                for res in results_val_lasso:\n","                    ## qui filtro per alpha\n","                    if (res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha):\n","                        filtered_results.append(res)\n","\n","                if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_lasso[(classifier, selector, alpha)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']),reverse=True)\n","sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n","\n","#sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']),reverse=True)\n","#sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","# Combina i risultati di entrambi i grid search\n","sorted_results = sorted_results_others + sorted_results_lasso\n","\n","sorted_results = sorted(sorted_results, key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n","#sorted_results = sorted(sorted_results, key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### mostro migliori combo"]},{"cell_type":"code","execution_count":286,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Migliori 10 combinazioni di parametri:\n","\n","#1:\n","Classifier: ensemble\n","Selector: lasso\n","Alpha: 0.19275862068965519\n","Performance medie sul val set: \n","ROC AUC = 0.7151851851851851 (std = 0.1769195260280399), Balanced Accuracy = 0.6852777777777778 (std = 0.14257808668399616)\n","Metrics on the TEST set:\n","Selected Features: [ 0  3  4  5  6  7  8  9 10 11 13 15 16 17 18 19 20 21 22 23 25 28 29 32\n"," 33 35 36 37 38 39 40 41]\n","ROC AUC: 0.6666666666666667\n","F1 Score: 0.6\n","Accuracy: 0.6923076923076923\n","Balanced Accuracy: 0.7083333333333333\n","Confusion Matrix: \n","[[18  9]\n"," [ 3  9]]\n","\n","#2:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.5\n","Performance medie sul val set: \n","ROC AUC = 0.725570987654321 (std = 0.18573549918956875), Balanced Accuracy = 0.6808333333333333 (std = 0.15791061993700387)\n","Metrics on the TEST set:\n","Selected Features: [ 0  4  5  8 11 13 15 17 18 19 20 21 22 23 25 29 30 33 34 37 38 39 40]\n","ROC AUC: 0.625\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Balanced Accuracy: 0.6111111111111112\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#3:\n","Classifier: RandomForest\n","Selector: logistic\n","Num_features: 15\n","Performance medie sul val set: \n","ROC AUC = 0.6881635802469136 (std = 0.1330111584914087), Balanced Accuracy = 0.6808333333333333 (std = 0.0996783019964169)\n","Metrics on the TEST set:\n","Selected Features: [12 21  8 19 18 22 30 38  6 15  1 37 31 11 10]\n","ROC AUC: 0.6867283950617283\n","F1 Score: 0.5806451612903226\n","Accuracy: 0.6666666666666666\n","Balanced Accuracy: 0.6898148148148149\n","Confusion Matrix: \n","[[17 10]\n"," [ 3  9]]\n","\n","#4:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 2\n","Performance medie sul val set: \n","ROC AUC = 0.6429320987654321 (std = 0.13951237797573318), Balanced Accuracy = 0.6791666666666666 (std = 0.14669388951903284)\n","Metrics on the TEST set:\n","Selected Features: [12 21]\n","ROC AUC: 0.5864197530864198\n","F1 Score: 0.4117647058823529\n","Accuracy: 0.48717948717948717\n","Balanced Accuracy: 0.5138888888888888\n","Confusion Matrix: \n","[[12 15]\n"," [ 5  7]]\n","\n","#5:\n","Classifier: ensemble\n","Selector: logistic\n","Num_features: 2\n","Performance medie sul val set: \n","ROC AUC = 0.6602777777777777 (std = 0.17841033297872697), Balanced Accuracy = 0.6777777777777778 (std = 0.18482922965754758)\n","Metrics on the TEST set:\n","Selected Features: [12 21]\n","ROC AUC: 0.5308641975308642\n","F1 Score: 0.4\n","Accuracy: 0.46153846153846156\n","Balanced Accuracy: 0.49537037037037035\n","Confusion Matrix: \n","[[11 16]\n"," [ 5  7]]\n","\n","#6:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 16\n","Performance medie sul val set: \n","ROC AUC = 0.7170216049382716 (std = 0.14796225960009382), Balanced Accuracy = 0.673611111111111 (std = 0.10721016771616577)\n","Metrics on the TEST set:\n","Selected Features: [12 21  8 19 18 22 30 38  6 15  1 37 31 11 10 29]\n","ROC AUC: 0.6635802469135802\n","F1 Score: 0.5517241379310345\n","Accuracy: 0.6666666666666666\n","Balanced Accuracy: 0.6666666666666666\n","Confusion Matrix: \n","[[18  9]\n"," [ 4  8]]\n","\n","#7:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.3463793103448276\n","Performance medie sul val set: \n","ROC AUC = 0.7045216049382715 (std = 0.19750135865428), Balanced Accuracy = 0.6708333333333334 (std = 0.10805252066574947)\n","Metrics on the TEST set:\n","Selected Features: [ 0  4  5  6  7  8 11 13 15 16 17 18 19 20 21 22 23 24 29 30 33 34 35 37\n"," 38 39 40 41]\n","ROC AUC: 0.6342592592592592\n","F1 Score: 0.4827586206896552\n","Accuracy: 0.6153846153846154\n","Balanced Accuracy: 0.6064814814814815\n","Confusion Matrix: \n","[[17 10]\n"," [ 5  7]]\n","\n","#8:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 3\n","Performance medie sul val set: \n","ROC AUC = 0.670679012345679 (std = 0.0717115366336462), Balanced Accuracy = 0.6705555555555556 (std = 0.06817166965250211)\n","Metrics on the TEST set:\n","Selected Features: [12 21  8]\n","ROC AUC: 0.654320987654321\n","F1 Score: 0.42857142857142855\n","Accuracy: 0.5897435897435898\n","Balanced Accuracy: 0.5648148148148149\n","Confusion Matrix: \n","[[17 10]\n"," [ 6  6]]\n","\n","#9:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.0903448275862069\n","Performance medie sul val set: \n","ROC AUC = 0.6956018518518519 (std = 0.19794901728241218), Balanced Accuracy = 0.6680555555555555 (std = 0.1312591854516555)\n","Metrics on the TEST set:\n","Selected Features: [ 0  3  4  5  6  7  8  9 10 11 13 15 16 17 18 19 20 21 22 23 24 25 28 29\n"," 30 31 32 33 35 36 37 38 39 40 41]\n","ROC AUC: 0.677469135802469\n","F1 Score: 0.5517241379310345\n","Accuracy: 0.6666666666666666\n","Balanced Accuracy: 0.6666666666666666\n","Confusion Matrix: \n","[[18  9]\n"," [ 4  8]]\n","\n","#10:\n","Classifier: RandomForest\n","Selector: lasso\n","Alpha: 0.31224137931034485\n","Performance medie sul val set: \n","ROC AUC = 0.7379938271604939 (std = 0.18440217208631077), Balanced Accuracy = 0.6669444444444445 (std = 0.15751922771130333)\n","Metrics on the TEST set:\n","Selected Features: [ 0  4  5  6  7  8  9 11 13 15 16 17 18 19 20 21 22 23 29 30 32 33 34 35\n"," 37 38 39 40 41]\n","ROC AUC: 0.6358024691358024\n","F1 Score: 0.5333333333333333\n","Accuracy: 0.6410256410256411\n","Balanced Accuracy: 0.6481481481481481\n","Confusion Matrix: \n","[[17 10]\n"," [ 4  8]]\n"]}],"source":["n=10\n","best_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_combinations, start=1):\n","\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","        print(f\"Alpha: {params[2]}\")\n","    else:\n","        print(f\"Num_features: {params[2]}\")\n","\n","    print(f\"Performance medie sul val set: \\nROC AUC = {metrics['avg_roc_auc']} (std = {metrics['std_roc_auc']}), \"f\"Balanced Accuracy = {metrics['avg_balaccuracy']} (std = {metrics['std_balaccuracy']})\")\n","\n","\n","\n","    for p in range (0, len(results_test_others)):\n","            if(params[1]=='lasso'):\n","                if(results_test_lasso[p]['classifier']==params[0] and results_test_lasso[p]['alpha']==params[2]):\n","                        best_case=results_test_lasso[p]\n","                        break\n","            else:     \n","                if(results_test_others[p]['classifier']==params[0] and results_test_others[p]['selector']==params[1] and results_test_others[p]['num_features']==params[2]):\n","                        best_case=results_test_others[p]\n","                        break\n","\n","    \n","    print(\"Metrics on the TEST set:\")\n","\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## FINETUNAMENTO SEEDs\n"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 2, 3, 4]\n"]}],"source":["\n","seeds = list(range(1, 5)) \n","print(seeds)\n","\n","\n","#alpha_1 = np.linspace(0.01, 0.6, 30).tolist() ## RANGE PER RESNET\n","\n","alpha_1 = np.linspace(0.005, 0.5, 30).tolist() ## RANGE PER VGG\n","\n","#alpha_2 = np.linspace(0, 0.005, 21).tolist()\n","\n","alpha_values=alpha_1 \n","\n","\n","thresholds=[0.5]\n","\n","#selectors=['lasso', 'mrmr','rf', 'logistic']\n","\n","#classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n","\n","classifiers=['SVM', 'ensemble','RandomForest', 'Logistic']\n","selectors=['mrmr','rf', 'logistic', 'lasso']\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["template_dict = {\n","                'seedSmote':None,\n","                'seedKFold': None,\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'selected_features': [],\n","                'balanced accuracy': None\n","                    }\n","\n","\n","results_val_others = [template_dict.copy() for _ in range(900000)]\n","results_val_others.append(template_dict.copy())\n","\n","results_val_lasso = [template_dict.copy() for _ in range(900000)]\n","results_val_lasso.append(template_dict.copy())\n","\n","results_test_others = [template_dict.copy() for _ in range(900000)]\n","results_test_others.append(template_dict.copy())\n","\n","results_test_lasso = [template_dict.copy() for _ in range(900000)]\n","results_test_lasso.append(template_dict.copy())\n","\n","k=0\n","u=0\n","n_folds=5\n","\n","for seed1 in seeds:\n","     for seed2 in seeds:\n","        \n","        smote = SMOTE(random_state=seed1)\n","\n","        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed2)\n","\n","        for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","            print(\"Starting with fold:\", fold_idx)\n","\n","            x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","            y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","            x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n","\n","            #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n","\n","\n","            for i, classifier in enumerate(classifiers):\n","                    print(\"Starting with classifier:\", classifier)\n","                    for j, selector in enumerate(selectors):\n","                        print(\"Starting with selector:\", selector)\n","\n","                        if(selector=='lasso'):\n","\n","                            for alpha in alpha_values:\n","                                #print(\"Doing alpha \", alpha )\n","                                classi= classifierinitialization(classifier)\n","                                best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                                \n","                                if(best_case_val==0):\n","                                    continue\n","                                \n","                                results_val_lasso[k] = {\n","                                                    'seedSmote': seed1,\n","                                                    'seedKFold': seed2,\n","                                                    'fold': fold_idx,\n","                                                    'classifier': classifier,\n","                                                    'selector': selector,\n","                                                    'alpha': alpha,\n","                                                    'num_features': best_case_val['num_features'],\n","                                                    'selected_features': best_case_val['selected_features'],\n","                                                    'pr_auc': best_case_val['pr_auc'],\n","                                                    'roc_auc': best_case_val['roc_auc'],\n","                                                    'f1': best_case_val['f1'],\n","                                                    'accuracy': best_case_val['accuracy'],\n","                                                    'confusion_matrix': best_case_val['confusion_matrix'],\n","                                                    'balanced accuracy': best_case_val['balanced accuracy'],\n","                                                    }\n","\n","                                #print(best_case_val['num_features'])\n","                                \n","\n","                                if(fold_idx==0):\n","                                    classi= classifierinitialization(classifier)\n","                                    best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","                                    if(best_case_test==0):\n","                                        continue\n","                                    results_test_lasso[u] = {\n","                                                        'seedSmote': seed1,\n","                                                        'seedKFold': seed2,\n","                                                        'classifier': classifier,\n","                                                        'selector': selector,\n","                                                        'alpha': alpha,\n","                                                        'num_features': best_case_test['num_features'],\n","                                                        'selected_features': best_case_test['selected_features'],\n","                                                        'pr_auc': best_case_test['pr_auc'],\n","                                                        'roc_auc': best_case_test['roc_auc'],\n","                                                        'f1': best_case_test['f1'],\n","                                                        'accuracy': best_case_test['accuracy'],\n","                                                        'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                        'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                        }\n","                                    u=u+1\n","                                k = k + 1\n","\n","                        else:\n","                            #limit=len(x_train_reduced[0]) + 1\n","                            limit=30\n","                            for t in range(1, limit):\n","                                    classi= classifierinitialization(classifier)\n","\n","                                    best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                            \n","                                        \n","                                    results_val_others[k] = {\n","                                                        'seedSmote': seed1,\n","                                                        'seedKFold': seed2,\n","                                                        'fold': fold_idx,\n","                                                        'classifier': classifier,\n","                                                        'selector': selector,\n","                                                        'alpha': 0,\n","                                                        'num_features': t,\n","                                                        'selected_features': best_case_val['selected_features'],\n","                                                        'pr_auc': best_case_val['pr_auc'],\n","                                                        'roc_auc': best_case_val['roc_auc'],\n","                                                        'f1': best_case_val['f1'],\n","                                                        'accuracy': best_case_val['accuracy'],\n","                                                        'confusion_matrix': best_case_val['confusion_matrix'],\n","                                                        'balanced accuracy': best_case_val['balanced accuracy'],\n","                                                        }\n","                                    #print(results_val_others[k]['f1'])\n","\n","                                    if(fold_idx==0):\n","                                        classi= classifierinitialization(classifier)\n","                                        best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                                        \n","                                        results_test_others[u] = {\n","                                                            'seedSmote': seed1,\n","                                                            'seedKFold': seed2,\n","                                                            'classifier': classifier,\n","                                                            'selector': selector,\n","                                                            'alpha': 0,\n","                                                            'num_features': t,\n","                                                            'selected_features': best_case_test['selected_features'],\n","                                                            'pr_auc': best_case_test['pr_auc'],\n","                                                            'roc_auc': best_case_test['roc_auc'],\n","                                                            'f1': best_case_test['f1'],\n","                                                            'accuracy': best_case_test['accuracy'],\n","                                                            'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                            'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                            }\n","                                        u=u+1\n","\n","                                    k = k + 1"]},{"cell_type":"code","execution_count":239,"metadata":{},"outputs":[],"source":["results_test_lasso = [entry for entry in results_test_lasso if entry['classifier'] is not None]\n","results_val_lasso= [entry for entry in results_val_lasso if entry['classifier'] is not None]\n","results_test_others = [entry for entry in results_test_others if entry['classifier'] is not None]\n","results_val_others = [entry for entry in results_val_others if entry['classifier'] is not None]"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[],"source":["\n","grid_results_others = {}\n","grid_results_lasso = {}\n","\n","selectors = ['mrmr', 'rf', 'logistic']\n","\n","for seed1 in seeds:\n","     for seed2 in seeds:\n","        # Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","        for classifier in classifiers:\n","                    #print(f\"Sto iniziando classifier {classifier}\")\n","                    for selector in selectors:\n","                            #print(f\"Sto iniziando selector {selector}\")\n","                            for num_features in num_features_range:\n","                                    \n","                                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                                    filtered_results=[]\n","                                    for res in results_val_others:\n","                                        ## qui filtro per num_features\n","                                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features and res['seedKFold']== seed2 and res['seedSmote']== seed1):\n","                                            filtered_results.append(res)\n","                                \n","                                    if filtered_results:\n","                                        f1_values = [res['f1'] for res in filtered_results]\n","                                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                                        # Calcola le medie delle metriche\n","                                        avg_f1 = sum(f1_values) / len(f1_values)\n","                                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                                        # Calcola la deviazione standard delle metriche\n","                                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                                        grid_results_others[(classifier, selector, num_features, seed1, seed2)] = {\n","                                            'avg_f1': avg_f1,\n","                                            'std_f1': std_f1,\n","                                            'avg_balaccuracy': avg_balaccuracy,\n","                                            'std_balaccuracy': std_balaccuracy,\n","                                            'avg_roc_auc': avg_roc,\n","                                            'std_roc_auc': std_roc_auc,\n","                                            'seedSmote': seed1,\n","                                            'seedKFold': seed2\n","                                        }\n","\n","\n","\n","## ORA PER LASSO\n","selectors = ['lasso']\n","for seed1 in seeds:\n","     for seed2 in seeds:\n","        for classifier in classifiers:\n","                    #print(f\"Sto iniziando classifier {classifier}\")\n","                    for selector in selectors:\n","                        #print(f\"Sto iniziando selector {selector}\")\n","                        for alpha in alpha_values:\n","                                filtered_results = []\n","                                for res in results_val_lasso:\n","                                    ## qui filtro per alpha\n","                                    if (res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha and res['seedKFold']== seed2 and res['seedSmote']== seed1):\n","                                        filtered_results.append(res)\n","\n","                                if filtered_results:\n","                                        f1_values = [res['f1'] for res in filtered_results]\n","                                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                                        # Calcola le medie delle metriche\n","                                        avg_f1 = sum(f1_values) / len(f1_values)\n","                                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                                        # Calcola la deviazione standard delle metriche\n","                                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                                        grid_results_lasso[(classifier, selector, alpha, seed1, seed2)] = {\n","                                            'avg_f1': avg_f1,\n","                                            'std_f1': std_f1,\n","                                            'avg_balaccuracy': avg_balaccuracy,\n","                                            'std_balaccuracy': std_balaccuracy,\n","                                            'avg_roc_auc': avg_roc,\n","                                            'std_roc_auc': std_roc_auc,\n","                                            'seedSmote': seed1,\n","                                            'seedKFold': seed2\n","                                        }"]},{"cell_type":"code","execution_count":268,"metadata":{},"outputs":[],"source":["# Liste per memorizzare i migliori risultati, con seed inclusi nei valori\n","best_results_others = []\n","best_results_lasso = []\n","\n","# Funzione di confronto che tiene conto prima di \"balanced accuracy\" e poi di \"roc_auc\"\n","def is_better(result1, result2):\n","    if result1['avg_balaccuracy'] > result2['avg_balaccuracy']:\n","        return True\n","    elif result1['avg_balaccuracy'] == result2['avg_balaccuracy']:\n","        return result1['avg_roc_auc'] > result2['avg_roc_auc']\n","    return False\n","\n","# Filtraggio per grid_results_others: scegli il migliore per ogni coppia (seed1, seed2)\n","for key, result in grid_results_others.items():\n","    classifier, selector, num_features, seed1, seed2 = key\n","    seed_pair = (seed1, seed2)\n","    \n","    # Cerca se esiste già una combinazione con la stessa coppia di seed\n","    found = False\n","    for entry in best_results_others:\n","        if (entry['seed1'] == seed1 and entry['seed2'] == seed2):\n","            found = True\n","            # Se esiste, confronta le metriche e tieni il migliore\n","            if is_better(result, entry):\n","                entry.update({\n","                    'classifier': classifier,\n","                    'selector': selector,\n","                    'num_features': num_features,\n","                    'avg_f1': result['avg_f1'],\n","                    'std_f1': result['std_f1'],\n","                    'avg_balaccuracy': result['avg_balaccuracy'],\n","                    'std_balaccuracy': result['std_balaccuracy'],\n","                    'avg_roc_auc': result['avg_roc_auc'],\n","                    'std_roc_auc': result['std_roc_auc'],\n","                    'seed1': seed1,\n","                    'seed2': seed2\n","                })\n","            break\n","    \n","    # Se non esiste, aggiungi la nuova combinazione\n","    if not found:\n","        best_results_others.append({\n","            'classifier': classifier,\n","            'selector': selector,\n","            'num_features': num_features,\n","            'avg_f1': result['avg_f1'],\n","            'std_f1': result['std_f1'],\n","            'avg_balaccuracy': result['avg_balaccuracy'],\n","            'std_balaccuracy': result['std_balaccuracy'],\n","            'avg_roc_auc': result['avg_roc_auc'],\n","            'std_roc_auc': result['std_roc_auc'],\n","            'seed1': seed1,\n","            'seed2': seed2\n","        })\n","\n","# Filtraggio per grid_results_lasso: scegli il migliore per ogni coppia (seed1, seed2)\n","for key, result in grid_results_lasso.items():\n","    classifier, selector, alpha, seed1, seed2 = key\n","    seed_pair = (seed1, seed2)\n","    \n","    # Cerca se esiste già una combinazione con la stessa coppia di seed\n","    found = False\n","    for entry in best_results_lasso:\n","        if (entry['seed1'] == seed1 and entry['seed2'] == seed2):\n","            found = True\n","            # Se esiste, confronta le metriche e tieni il migliore\n","            if is_better(result, entry):\n","                entry.update({\n","                    'classifier': classifier,\n","                    'selector': selector,\n","                    'alpha': alpha,\n","                    'avg_f1': result['avg_f1'],\n","                    'std_f1': result['std_f1'],\n","                    'avg_balaccuracy': result['avg_balaccuracy'],\n","                    'std_balaccuracy': result['std_balaccuracy'],\n","                    'avg_roc_auc': result['avg_roc_auc'],\n","                    'std_roc_auc': result['std_roc_auc'],\n","                    'seed1': seed1,\n","                    'seed2': seed2\n","                })\n","            break\n","    \n","    # Se non esiste, aggiungi la nuova combinazione\n","    if not found:\n","        best_results_lasso.append({\n","            'classifier': classifier,\n","            'selector': selector,\n","            'alpha': alpha,\n","            'avg_f1': result['avg_f1'],\n","            'std_f1': result['std_f1'],\n","            'avg_balaccuracy': result['avg_balaccuracy'],\n","            'std_balaccuracy': result['std_balaccuracy'],\n","            'avg_roc_auc': result['avg_roc_auc'],\n","            'std_roc_auc': result['std_roc_auc'],\n","            'seed1': seed1,\n","            'seed2': seed2\n","        })\n","\n","# Ora best_results_others e best_results_lasso contengono solo un elemento per ogni coppia di seed (seed1, seed2).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","import pickle\n","\n","# Salva i risultati in un file pickle\n","with open('/Users/alessiamenozzi/Desktop/best_results_others_VGG.pkl', 'wb') as f:\n","    pickle.dump(best_results_others, f)\n","\n","with open('/Users/alessiamenozzi/Desktop/best_results_lasso_VGG.pkl', 'wb') as f:\n","    pickle.dump(best_results_lasso, f)\n","\n"]},{"cell_type":"code","execution_count":287,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Combinazioni con balanced accuracy > 0.7 sul test set:\n"]},{"ename":"KeyError","evalue":"'seedKFold'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[287], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Cerca la combinazione corrispondente nei risultati del test set 'others'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results_test_others)):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (results_test_others[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         results_test_others[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         results_test_others[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mresults_test_others\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseedKFold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         results_test_others[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseedSmote\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed2\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     14\u001b[0m         best_case \u001b[38;5;241m=\u001b[39m results_test_others[p]\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mKeyError\u001b[0m: 'seedKFold'"]}],"source":["print(f\"Combinazioni con balanced accuracy > 0.7 sul test set:\")\n","\n","# Itera su tutte le migliori combinazioni trovate nei risultati di validazione di 'others'\n","for i, result in enumerate(best_results_others, start=1):\n","    best_case = None  # Inizializza best_case\n","    # Cerca la combinazione corrispondente nei risultati del test set 'others'\n","    for p in range(len(results_test_others)):\n","        if (results_test_others[p]['classifier'] == result['classifier'] and\n","            results_test_others[p]['selector'] == result['selector'] and\n","            results_test_others[p]['num_features'] == result['num_features'] and\n","            results_test_others[p]['seedKFold'] == result['seed1'] and\n","            results_test_others[p]['seedSmote'] == result['seed2']):\n","            \n","            best_case = results_test_others[p]\n","            break\n","    \n","    # Controlla se la balanced accuracy sul test è maggiore di 0.7\n","    if best_case and best_case['balanced accuracy'] > 0.68:\n","        print(f\"\\n#{i}:\")\n","        print(f\"Classifier: {result['classifier']}\")\n","        print(f\"Selector: {result['selector']}\")\n","        print(f\"Num_features: {result['num_features']}\")\n","        print(f\"Seed Kfold: {result['seed1']}\")\n","        print(f\"Seed Smote: {result['seed2']}\")\n","        \n","        # Stampa le performance medie dal validation set\n","        print(f\"Performance medie sul validation set: \\nROC AUC = {result['avg_roc_auc']} (std = {result['std_roc_auc']}), \"\n","              f\"Balanced Accuracy = {result['avg_balaccuracy']} (std = {result['std_balaccuracy']})\")\n","        \n","        # Stampa le metriche sul test set\n","        print(\"Metrics on the TEST set:\")\n","        print(f\"Selected Features: {best_case['selected_features']}\")\n","        print(f\"ROC AUC: {best_case['roc_auc']}\")\n","        print(f\"F1 Score: {best_case['f1']}\")\n","        print(f\"Accuracy: {best_case['accuracy']}\")\n","        print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n","        print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n","\n"]},{"cell_type":"code","execution_count":278,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","#17:\n","Classifier: ensemble\n","Selector: lasso\n","Alpha: 0.19275862068965519\n","Seed Kfold: 1\n","Seed Smote: 1\n","Performance medie sul validation set: \n","ROC AUC = 0.7151851851851851 (std = 0.1769195260280399), Balanced Accuracy = 0.6852777777777778 (std = 0.14257808668399616)\n","Metrics on the TEST set:\n","Selected Features: [ 0  3  4  5  6  7  8  9 10 11 13 15 16 17 18 19 20 21 22 23 25 28 29 32\n"," 33 35 36 37 38 39 40 41]\n","ROC AUC: 0.6666666666666667\n","F1 Score: 0.6\n","Accuracy: 0.6923076923076923\n","Balanced Accuracy: 0.7083333333333333\n","Confusion Matrix: \n","[[18  9]\n"," [ 3  9]]\n"]}],"source":["# Itera su tutte le migliori combinazioni trovate nei risultati di validazione di 'lasso'\n","for i, result in enumerate(best_results_lasso, start=len(best_results_others) + 1):\n","    best_case = None  # Inizializza best_case\n","    # Cerca la combinazione corrispondente nei risultati del test set 'lasso'\n","    for p in range(len(results_test_lasso)):\n","        if (results_test_lasso[p]['classifier'] == result['classifier'] and\n","            results_test_lasso[p]['alpha'] == result['alpha'] and\n","            results_test_lasso[p]['seedKFold'] == result['seed1'] and\n","            results_test_lasso[p]['seedSmote'] == result['seed2']):\n","            \n","            best_case = results_test_lasso[p]\n","            break\n","    \n","    # Controlla se la balanced accuracy sul test è maggiore di 0.7\n","    if best_case and best_case['balanced accuracy'] > 0.7:\n","        print(f\"\\n#{i}:\")\n","        print(f\"Classifier: {result['classifier']}\")\n","        print(f\"Selector: {result['selector']}\")\n","        print(f\"Alpha: {result['alpha']}\")\n","        print(f\"Seed Kfold: {result['seed1']}\")\n","        print(f\"Seed Smote: {result['seed2']}\")\n","        \n","        # Stampa le performance medie dal validation set\n","        print(f\"Performance medie sul validation set: \\nROC AUC = {result['avg_roc_auc']} (std = {result['std_roc_auc']}), \"\n","              f\"Balanced Accuracy = {result['avg_balaccuracy']} (std = {result['std_balaccuracy']})\")\n","        \n","        # Stampa le metriche sul test set\n","        print(\"Metrics on the TEST set:\")\n","        print(f\"Selected Features: {best_case['selected_features']}\")\n","        print(f\"ROC AUC: {best_case['roc_auc']}\")\n","        print(f\"F1 Score: {best_case['f1']}\")\n","        print(f\"Accuracy: {best_case['accuracy']}\")\n","        print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n","        print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5686764,"sourceId":9375373,"sourceType":"datasetVersion"},{"datasetId":5686788,"sourceId":9375404,"sourceType":"datasetVersion"},{"datasetId":5687116,"sourceId":9375826,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
