{"cells":[{"cell_type":"markdown","metadata":{},"source":["## import"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T14:41:29.243721Z","iopub.status.busy":"2024-09-12T14:41:29.243296Z","iopub.status.idle":"2024-09-12T14:41:29.260564Z","shell.execute_reply":"2024-09-12T14:41:29.259665Z","shell.execute_reply.started":"2024-09-12T14:41:29.243682Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","# Import libraries\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import ttest_ind\n","from xgboost import XGBClassifier\n","import statistics\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import balanced_accuracy_score\n","\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["## caricamento dati"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento labels pazienti"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels: [0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0\n"," 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n"," 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0\n"," 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n","Number of labels: 129\n","Patient Names:  [5, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 133, 135, 136, 137, 138, 139, 141, 142, 144, 146, 147, 149, 150, 153, 155, 158, 159, 161, 163, 166, 168, 169, 170, 171, 175, 176, 178, 182, 183, 188, 189, 190, 193, 197, 199, 200, 205]\n"]}],"source":["\n","file_path = \"../CSV/data_rad_clin_DEF.csv\"\n","\n","data = pd.read_csv(file_path)\n","labels_column = data['label']\n","labels = labels_column.astype(int).tolist()\n","\n","labels=np.array(labels)\n","\n","# Estrazione dei numeri dai nomi dei pazienti\n","loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n","\n","print(\"Labels:\", labels)\n","print(\"Number of labels:\", len(labels))\n","print(\"Patient Names: \", loaded_patients )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features encoder"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 3.4178352   8.718901    0.69966245 ...  0.3986745   0.34853888\n","   1.7183607 ]\n"," [ 8.604453    8.845457    1.8935882  ...  0.          0.80906904\n","   4.6214924 ]\n"," [ 1.2216972   7.3100176   0.34905487 ...  0.          1.2966236\n","   0.9705608 ]\n"," ...\n"," [ 0.96702075  4.432042    0.         ...  0.          6.9164467\n","   0.8192799 ]\n"," [16.770971   13.8288765   1.3877221  ...  0.          0.7713363\n","   3.1712778 ]\n"," [12.191864    9.345943    2.9560928  ...  0.          1.3538481\n","   2.296222  ]]\n","(129, 2048)\n"]}],"source":["#file_path = \"../CSV/EncodersSliceMaggiore/VGG19_Slice_Maggiore.csv\"\n","#file_path = \"../CSV/EncodersSliceMaggiore/InceptionV3_Slice_Maggiore.csv\"\n","file_path = \"../CSV/EncodersSliceMaggiore/RESNET50_Slice_Maggiore.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","\n","\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","df_features = df_ordered.drop(columns=['Unnamed: 0'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features radiomica"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[5.83888273e-01 2.49810487e+01 2.57099203e+01 ... 5.69700030e+03\n","  5.01293376e-01 1.88681815e+02]\n"," [8.68120272e-01 2.78353641e+01 2.75136330e+01 ... 1.17856494e+04\n","  4.99502216e-01 2.32884640e+02]\n"," [6.68428011e-01 3.34967625e+01 3.44818793e+01 ... 1.10016612e+03\n","  1.37685835e-01 1.17271924e+02]\n"," ...\n"," [8.95387032e-01 3.24479655e+01 2.80178515e+01 ... 3.74357530e+02\n","  3.76839859e-01 4.56595117e+01]\n"," [7.82116308e-01 2.65896102e+01 2.56320112e+01 ... 1.71247332e+04\n","  8.63664634e-01 1.86559244e+02]\n"," [5.58702485e-01 3.61138047e+01 3.58468967e+01 ... 1.35620356e+04\n","  4.73861210e-01 2.66695842e+02]]\n","(129, 474)\n"]}],"source":["file_path = \"../CSV/EncodersSliceMaggiore/Radiomica_Wavelet_2D.csv\"\n","#file_path = \"../CSV/EncodersSliceMaggiore/Radiomica_2D.csv\"\n","\n","df = pd.read_csv(file_path, sep=',')\n","#df = df.astype(float)\n","\n","# Colonne da rimuovere SOLO PER RADIOMICA\n","columns_to_remove = [\n","    'Slice',\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","df_cleaned = df.drop(columns=columns_to_remove)\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)  "]},{"cell_type":"markdown","metadata":{},"source":["### caricamento pesi da autoencoder"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","import h5py\n","import cv2\n","\n","def estrai_immagine_massima_area_con_contorno(imagelist):\n","    \"\"\"Restituisce l'immagine con l'area più grande delimitata dal contorno di pixel non neri.\"\"\"\n","    max_area = 0\n","    max_image = None\n","\n","    for image in imagelist:\n","        # Crea una maschera per i pixel non neri (placca)\n","        mask = image > 0\n","        \n","        # Converti l'immagine in formato che OpenCV può elaborare\n","        mask_uint8 = mask.astype(np.uint8) * 255\n","\n","        # Trova i contorni nell'immagine\n","        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Considera solo il contorno più grande\n","        if contours:\n","            # Trova il contorno con la massima area\n","            largest_contour = max(contours, key=cv2.contourArea)\n","\n","            # Calcola l'area del contorno\n","            area = cv2.contourArea(largest_contour)\n","\n","            # Aggiorna se questa immagine ha un'area maggiore\n","            if area > max_area:\n","                max_area = area\n","                max_image = image\n","\n","    return max_image\n","\n","# Caricamento del file HDF5 con le immagini\n","h5_file_path = '../images_by_patient_final.h5'\n","loaded_class_images = []\n","\n","with h5py.File(h5_file_path, 'r') as h5_file:\n","    for key in h5_file.keys():\n","        images = np.array(h5_file[key])\n","        loaded_class_images.append(images)\n","\n","# Estrai l'immagine con l'area massima per ciascun paziente usando il nuovo criterio (contorno)\n","immagini_massime_per_paziente_contorno = []\n","\n","for imagelist in loaded_class_images:\n","    max_image = estrai_immagine_massima_area_con_contorno(imagelist)\n","    immagini_massime_per_paziente_contorno.append(max_image)\n","    "]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["64"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["len(immagini_massime_per_paziente_contorno[0][0])"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Lunghezza array immagini:  129\n","Shape immagini primo paziente:  (28, 64, 64)\n","Shape immagini secondo paziente:  (22, 64, 64)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m features_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m loaded_class_images[i]:\n\u001b[0;32m---> 41\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     features_list\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[1;32m     43\u001b[0m fetures_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features_list)\n","Cell \u001b[0;32mIn[76], line 30\u001b[0m, in \u001b[0;36mget_features_from_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     28\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Aggiungi canale (per immagini in bianco e nero)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Aggiungi dimensione batch\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(features)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:442\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    440\u001b[0m ):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:625\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[0;32m--> 625\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[1;32m    627\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[1;32m    628\u001b[0m         dataset\n\u001b[1;32m    629\u001b[0m     )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:634\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:232\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_options(options)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m--> 232\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    234\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2344\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[0;32m-> 2344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/flat_map_op.py:42\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure\u001b[38;5;241m.\u001b[39m_element_spec\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m---> 42\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:2426\u001b[0m, in \u001b[0;36mflat_map_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   2425\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2426\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2427\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlatMapDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2429\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   2431\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","h5_file_path = '../images_by_patient_final.h5'\n","loaded_class_images=[]\n","\n","# Apri il file .h5 e carica le immagini in loaded_class_images\n","with h5py.File(h5_file_path, 'r') as h5_file:\n","    # Carica ogni gruppo di immagini come un array numpy\n","    loaded_class_images = {key: np.array(h5_file[key]) for key in h5_file.keys()}\n","\n","loaded_class_images= {int(key.split('_')[1]): images for key, images in loaded_class_images.items()}\n","\n","print(\"Lunghezza array immagini: \", len(loaded_class_images))\n","print(\"Shape immagini primo paziente: \", loaded_class_images[0].shape)\n","print(\"Shape immagini secondo paziente: \", loaded_class_images[1].shape)\n","\n","encoder = load_model(\"../AUTOENCODER/encoder_models/encoder_model32.h5\", compile=False)\n","\n","# Funzione per ottenere le feature da una singola immagine\n","def get_features_from_image(image):\n","    image = image.astype('float32')\n","    image = image / 255.0\n","    # Ottieni le feature dall'encoder\n","    if len(image.shape) == 2:  # Se l'immagine è 64x64\n","        image = np.expand_dims(image, axis=-1)  # Aggiungi canale (per immagini in bianco e nero)\n","    image = np.expand_dims(image, axis=0)  # Aggiungi dimensione batch\n","    features = encoder.predict(image, verbose=False)\n","    features = np.squeeze(features)\n","    return np.array(features)\n","\n","# Lista per salvare le feature delle immagini\n","patients = []\n","\n","# Ottieni le feature per ogni immagine nella lista\n","for i in range(len(loaded_class_images)):\n","    features_list = []\n","    for img in loaded_class_images[i]:\n","        features = get_features_from_image(img)\n","        features_list.append(features)\n","    fetures_list = np.array(features_list)\n","    patients.append(features_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import h5py\n","import cv2\n","\n","def estrai_immagine_massima_area_con_contorno(imagelist):\n","    \"\"\"Restituisce l'immagine con l'area più grande delimitata dal contorno di pixel non neri.\"\"\"\n","    max_area = 0\n","    max_image = None\n","\n","    for image in imagelist:\n","        # Crea una maschera per i pixel non neri (placca)\n","        mask = image > 0\n","        \n","        # Converti l'immagine in formato che OpenCV può elaborare\n","        mask_uint8 = mask.astype(np.uint8) * 255\n","\n","        # Trova i contorni nell'immagine\n","        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Considera solo il contorno più grande\n","        if contours:\n","            # Trova il contorno con la massima area\n","            largest_contour = max(contours, key=cv2.contourArea)\n","\n","            # Calcola l'area del contorno\n","            area = cv2.contourArea(largest_contour)\n","\n","            # Aggiorna se questa immagine ha un'area maggiore\n","            if area > max_area:\n","                max_area = area\n","                max_image = image\n","\n","    return max_image\n","\n","# Caricamento del file HDF5 con le immagini\n","h5_file_path = 'images_by_patient_final.h5'\n","loaded_class_images = []\n","\n","with h5py.File(h5_file_path, 'r') as h5_file:\n","    for key in h5_file.keys():\n","        images = np.array(h5_file[key])\n","        loaded_class_images.append(images)\n","\n","# Estrai l'immagine con l'area massima per ciascun paziente usando il nuovo criterio (contorno)\n","immagini_massime_per_paziente_contorno = []\n","aree_contorno = []\n","\n","for imagelist in loaded_class_images:\n","    max_image, max_area = estrai_immagine_massima_area_con_contorno(imagelist)\n","    immagini_massime_per_paziente_contorno.append(max_image)\n","    aree_contorno.append(max_area)\n","\n","# Calcola anche l'area utilizzando solo i pixel non neri (come facevi prima)\n","aree_non_nere = []\n","for imagelist in loaded_class_images:\n","    max_image = estrai_immagine_massima_area(imagelist)\n","    non_black_pixels = np.sum(max_image != 0)\n","    aree_non_nere.append(non_black_pixels)\n","\n","# Visualizza i risultati\n","print(\"Numero di immagini selezionate (una per paziente):\", len(immagini_massime_per_paziente_contorno))\n","print(\"Shape dell'immagine selezionata per il primo paziente (contorno):\", immagini_massime_per_paziente_contorno[0].shape)\n","\n","# Differenza tra area massimizzata col contorno e solo pixel non neri\n","differenze_tra_insiemi = np.array(aree_contorno) - np.array(aree_non_nere)\n","\n","# Visualizza la differenza di aree tra il nuovo metodo e il precedente\n","for i, diff in enumerate(differenze_tra_insiemi):\n","    print(f\"Diff. area paziente {i+1}: {diff}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.774442Z","iopub.status.busy":"2024-09-12T14:41:29.774064Z","iopub.status.idle":"2024-09-12T14:41:29.814876Z","shell.execute_reply":"2024-09-12T14:41:29.813996Z","shell.execute_reply.started":"2024-09-12T14:41:29.774406Z"},"trusted":true},"outputs":[],"source":["\n","## Rimozione feature correlation\n","def remove_highly_correlated_features(X, threshold=0.85):\n","    corr_matrix = np.corrcoef(X, rowvar=False)\n","    upper_triangle = np.triu(corr_matrix, k=1)\n","    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n","    X_reduced = np.delete(X, to_drop, axis=1)\n","    return X_reduced, to_drop\n","\n","## Rimozione features p_value\n","def remove_high_pvalue_features(X, y, alpha=0.05):\n","    selector = SelectKBest(score_func=f_classif, k='all')\n","    selector.fit(X, y)\n","    p_values = selector.pvalues_\n","    features_to_keep = np.where(p_values < alpha)[0]\n","    X_reduced = X[:, features_to_keep]\n","    return X_reduced, features_to_keep\n","\n","## FEATURE SELECTION LASSO\n","def select_features_with_lasso(X, y, alpha=0.001):\n","    \n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X, y)\n","    coefficients = lasso.coef_\n","    selected_features = np.where(coefficients != 0)[0]\n","    X_selected = X[:, selected_features]\n","\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION LOGISTIC\n","def logistic_regression_feature_selection(X, y, num_features):\n","    lr = LogisticRegression(max_iter=2000, random_state=42)\n","    lr.fit(X, y)\n","    coef_abs = np.abs(lr.coef_)\n","    feature_importances = np.mean(coef_abs, axis=0)\n","    selected_features = feature_importances.argsort()[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION MRMR\n","def mrmr_feature_selection(X, y, num_features):\n","    mi = mutual_info_classif(X, y, random_state=42)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n","    \n","    selected_features = []\n","    selected_indices = []\n","\n","    first_feature_index = np.argmax(mi)\n","    selected_features.append(first_feature_index)\n","    selected_indices.append(first_feature_index)\n","    \n","    for _ in range(num_features - 1):\n","        max_relevance = -np.inf\n","        selected_feature_index = -1\n","        \n","        for i in range(X.shape[1]):\n","            if i in selected_indices:\n","                continue\n","            \n","            relevance = mi[i]\n","            redundancy = np.mean(distances[i, selected_indices])\n","            \n","            mrmr_score = relevance - redundancy\n","            \n","            if mrmr_score > max_relevance:\n","                max_relevance = mrmr_score\n","                selected_feature_index = i\n","        \n","        selected_features.append(selected_feature_index)\n","        selected_indices.append(selected_feature_index)\n","\n","    X_selected = X[:, selected_indices]\n","    return X_selected, selected_indices\n","\n","## FEATURE SELECTION RANDOM FOREST\n","def rf_feature_selection(X, y, num_features):\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf.fit(X, y)\n","    feature_importances = rf.feature_importances_\n","    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","\n","## FEATURE SELECTION P_VALUE\n","# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n","# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n","\n","def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n","    p_values = []\n","    num_features_total = x_train_expanded.shape[1]\n","\n","    # Calcolo dei p-value per ciascuna feature\n","    for i in range(num_features_total):\n","        feature = x_train_expanded[:, i]\n","        group_0 = feature[y_train_expanded == 0]\n","        group_1 = feature[y_train_expanded == 1]\n","        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n","        p_values.append(p_val)\n","\n","\n","    p_values = np.array(p_values)\n","\n","    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n","    sorted_indices = np.argsort(p_values)\n","    sorted_indices = sorted_indices[:num_features]\n","\n","    x_train_selected = x_train_expanded[:, sorted_indices]\n","\n","    return x_train_selected, sorted_indices\n","\n","\n","\n","## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n","def filter_patients_features(filtered_patients, selected_features):\n","    filtered_patients_selected = []\n","\n","    for patient_features in filtered_patients:\n","        # Select only the features specified in selected_features\n","        patient_features_selected = patient_features[:, selected_features]\n","        filtered_patients_selected.append(patient_features_selected)\n","\n","    return filtered_patients_selected\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["## classificazione completa che ritorna la threshold migliore per la classificazione\n","def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n","    best_f1_score = 0\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n","        thresholds=[thresholds]\n","        \n","    \n","    for threshold in thresholds:\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            \n","            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n","\n","\n","            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n","                best_f1_score = f1\n","                best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'best_threshold': threshold,\n","                    'balanced accuracy': bal_acc\n","                }\n","\n","    return best_case\n","\n","\n","#####################################################################################################################################\n","\n","### questo ritorna le il vettore di probabilità senza fare la classificazione\n","def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if (len(selected_features)==0):\n","                    return [0],0,[0]\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","#####################################################################################################################################\n","\n","\n","### classificazione effettuata con una threshold specifica\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold,\n","                    'balanced accuracy': bal_acc\n","                }\n","                \n","            if not best_case:\n","                 print(\"Attenzione caso vuoto\") \n","            return best_case\n","\n","#####################################################################################################################################\n","\n","\n","# metodo che definisce la threshold ottimale attraverso Youden's J statistic (threshold_selection= 'y')\n","# oppure attraverso la distanza euclidea dalla curva ROC (threshold_selection= 'd')\n","def classification_method_selection(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, threshold_selection, mode=\"Val\", selected_features=[0]):\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","                if(len(selected_features)==0):\n","                    return 0\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        classi=classifierinitialization(classifier, X_selected, y_train_expanded )\n","        # Training del classificatore\n","        classi.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    roc_auc = roc_auc_score(y_test, y_proba_test)\n","    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","    pr_auc = auc(recall, precision)\n","        \n","    fpr,tpr,threshold=roc_curve(y_test,y_proba_test,pos_label=1)\n","    youden_j = tpr - fpr\n","    optimal_threshold = threshold[np.argmax(youden_j)]\n","\n","    ## due modalità \n","    if threshold_selection == 'y':\n","        youden_j = tpr - fpr\n","        optimal_threshold = threshold[np.argmax(youden_j)]\n","    elif threshold_selection == 'd':\n","        distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n","        optimal_threshold = threshold[np.argmin(distances)]\n","    else:\n","        print('Threshold non valida!')\n","        return None\n","\n","    \n","    y_pred_custom_test = (y_proba_test >= optimal_threshold).astype(int)\n","\n","    accuracy = accuracy_score(y_test, y_pred_custom_test)\n","    f1 = f1_score(y_test, y_pred_custom_test)\n","    conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","\n","    best_case = {\n","        'alpha': alpha,\n","        'num_features': number_features,\n","        'selected_features': selected_features,\n","        'pr_auc': pr_auc,\n","        'roc_auc': roc_auc,\n","        'f1': f1,\n","        'accuracy': accuracy,\n","        'confusion_matrix': conf,\n","        'best_threshold': optimal_threshold,\n","        'threshold_mode': threshold_selection\n","    }\n","\n","    return best_case\n","\n","def classifierinitialization(classifier):\n","    if classifier == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif classifier == 'Logistic':\n","                            classi = LogisticRegression(random_state=42, max_iter=2000)\n","    elif classifier == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif classifier == 'XgBoost':\n","                            classi = XGBClassifier(random_state=42)\n","    elif classifier == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation = 'logistic')\n","    elif classifier == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42, max_iter=2000)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'\n","                                )\n","    return classi"]},{"cell_type":"markdown","metadata":{},"source":["## split"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.977584Z","iopub.status.busy":"2024-09-12T14:41:29.977021Z","iopub.status.idle":"2024-09-12T14:41:29.982827Z","shell.execute_reply":"2024-09-12T14:41:29.981953Z","shell.execute_reply.started":"2024-09-12T14:41:29.977546Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of train patients:  90\n","Number of test patients:  39\n","Number of features for every image:  2048\n"]}],"source":["Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False)\n","\n","\n","print(\"Number of train patients: \", len(X_train))\n","print(\"Number of test patients: \", len(y_test))\n","\n","print(\"Number of features for every image: \", X_train[0].shape[0] )\n"]},{"cell_type":"markdown","metadata":{},"source":["## correlation e p_value"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.617818Z","iopub.status.busy":"2024-09-12T14:41:30.616974Z","iopub.status.idle":"2024-09-12T14:41:30.650271Z","shell.execute_reply":"2024-09-12T14:41:30.649099Z","shell.execute_reply.started":"2024-09-12T14:41:30.617778Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2048\n","(90, 1328)\n","(39, 1328)\n","(90, 44)\n","(39, 44)\n"]}],"source":["# Inizialmente, tutti gli indici delle feature sono mantenuti\n","original_features = np.arange(X_train.shape[1])\n","print(X_train.shape[1])\n","\n","## FEATURE CORRELATION\n","\n","X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.8)\n","X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n","original_features = np.delete(original_features, dropped_features)\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n","\n","# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n","\n","X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, Y_train, alpha=0.01)\n","X_test_reduced = X_test_reduced[:, features_to_keep]\n","original_features = original_features[features_to_keep]\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## parametri"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.820390Z","iopub.status.busy":"2024-09-12T14:41:30.820019Z","iopub.status.idle":"2024-09-12T14:41:30.825775Z","shell.execute_reply":"2024-09-12T14:41:30.824852Z","shell.execute_reply.started":"2024-09-12T14:41:30.820355Z"},"trusted":true},"outputs":[],"source":["alpha_res_inc = np.linspace(0.01, 0.6, 30).tolist() ## RANGE PER RESNET e INCEPETION\n","\n","alpha_vgg = np.linspace(0.005, 0.5, 30).tolist() ## RANGE PER VGG\n","\n","alpha_rad = np.linspace(0.001, 0.05, 30).tolist() ## range per radiomica\n","\n","\n","alpha_values=alpha_res_inc\n","#alpha_values.remove(0.0)\n","\n","\n","#thresholds=np.arange(0.4, 0.61, 0.01) \n","\n","thresholds=[0.5]\n","\n","#selectors=['lasso', 'mrmr','rf', 'logistic']\n","\n","classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n","#classifiers=['SVM', 'ensemble','RandomForest', 'Logistic']\n","selectors=['mrmr','rf', 'logistic', 'lasso']\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loop per Validation seed SPECIFICI"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'selected_features': [],\n","                'balanced accuracy': None\n","            }\n","\n","\n","results_val_others = [template_dict.copy() for _ in range(5000)]\n","results_val_others.append(template_dict.copy())\n","\n","results_val_lasso = [template_dict.copy() for _ in range(5000)]\n","results_val_lasso.append(template_dict.copy())\n","\n","results_test_others = [template_dict.copy() for _ in range(5000)]\n","results_test_others.append(template_dict.copy())\n","\n","results_test_lasso = [template_dict.copy() for _ in range(5000)]\n","results_test_lasso.append(template_dict.copy())\n","limit=30\n","\n","smote = SMOTE(random_state=10)\n"," \n","k=0\n","u=0\n","n_folds=5\n","\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=13)\n"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting with fold: 0\n","Starting with classifier: XgBoost\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 1\n","Starting with classifier: XgBoost\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 2\n","Starting with classifier: XgBoost\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 3\n","Starting with classifier: XgBoost\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 4\n","Starting with classifier: XgBoost\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n"]}],"source":["for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n","\n","    #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n","\n","\n","    for i, classifier in enumerate(classifiers):\n","            print(\"Starting with classifier:\", classifier)\n","            for j, selector in enumerate(selectors):\n","                print(\"Starting with selector:\", selector)\n","\n","                if(selector=='lasso'):\n","\n","                    for alpha in alpha_values:\n","                        #print(\"Doing alpha \", alpha )\n","                        classi= classifierinitialization(classifier)\n","                        best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                        \n","                        if(best_case_val==0):\n","                            continue\n","                        if(best_case_val['num_features']> limit):\n","                             continue\n","                        \n","                        results_val_lasso[k] = {\n","                                            'fold': fold_idx,\n","                                            'classifier': classifier,\n","                                            'selector': selector,\n","                                            'alpha': alpha,\n","                                            'num_features': best_case_val['num_features'],\n","                                            'selected_features': best_case_val['selected_features'],\n","                                            'pr_auc': best_case_val['pr_auc'],\n","                                            'roc_auc': best_case_val['roc_auc'],\n","                                            'f1': best_case_val['f1'],\n","                                            'accuracy': best_case_val['accuracy'],\n","                                            'confusion_matrix': best_case_val['confusion_matrix'],\n","                                            'balanced accuracy': best_case_val['balanced accuracy'],\n","                                            }\n","\n","                        #print(best_case_val['num_features'])\n","                        \n","\n","                        if(fold_idx==0):\n","                            classi= classifierinitialization(classifier)\n","                            best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","                            if(best_case_test==0):\n","                                continue\n","                            \n","                            results_test_lasso[u] = {\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': alpha,\n","                                                'num_features': best_case_test['num_features'],\n","                                                'selected_features': best_case_test['selected_features'],\n","                                                'pr_auc': best_case_test['pr_auc'],\n","                                                'roc_auc': best_case_test['roc_auc'],\n","                                                'f1': best_case_test['f1'],\n","                                                'accuracy': best_case_test['accuracy'],\n","                                                'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                }\n","                            u=u+1\n","                        k = k + 1\n","\n","                else:\n","                    #limit=len(x_train_reduced[0]) + 1\n","                    limit=30\n","                    for t in range(1, limit):\n","                            classi= classifierinitialization(classifier)\n","\n","                            best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                    \n","                                \n","                            results_val_others[k] = {\n","                                                'fold': fold_idx,\n","                                                'classifier': classifier,\n","                                                'selector': selector,\n","                                                'alpha': 0,\n","                                                'num_features': t,\n","                                                'selected_features': best_case_val['selected_features'],\n","                                                'pr_auc': best_case_val['pr_auc'],\n","                                                'roc_auc': best_case_val['roc_auc'],\n","                                                'f1': best_case_val['f1'],\n","                                                'accuracy': best_case_val['accuracy'],\n","                                                'confusion_matrix': best_case_val['confusion_matrix'],\n","                                                'balanced accuracy': best_case_val['balanced accuracy'],\n","                                                }\n","                            #print(results_val_others[k]['f1'])\n","\n","                            if(fold_idx==0):\n","                                classi= classifierinitialization(classifier)\n","                                best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","                                \n","                                results_test_others[u] = {\n","                                                    'classifier': classifier,\n","                                                    'selector': selector,\n","                                                    'alpha': 0,\n","                                                    'num_features': t,\n","                                                    'selected_features': best_case_test['selected_features'],\n","                                                    'pr_auc': best_case_test['pr_auc'],\n","                                                    'roc_auc': best_case_test['roc_auc'],\n","                                                    'f1': best_case_test['f1'],\n","                                                    'accuracy': best_case_test['accuracy'],\n","                                                    'confusion_matrix': best_case_test['confusion_matrix'],\n","                                                    'balanced accuracy': best_case_test['balanced accuracy'],\n","                                                    }\n","                                u=u+1\n","\n","                            k = k + 1"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Filtered results_test_lasso: 174 entries remaining\n","Filtered results_val_lasso: 870 entries remaining\n","Filtered results_test_others: 522 entries remaining\n","Filtered results_val_others: 2610 entries remaining\n"]}],"source":["results_test_lasso = [entry for entry in results_test_lasso if entry['classifier'] is not None]\n","print(f\"Filtered results_test_lasso: {len(results_test_lasso)} entries remaining\")\n","results_val_lasso= [entry for entry in results_val_lasso if entry['classifier'] is not None]\n","print(f\"Filtered results_val_lasso: {len(results_val_lasso)} entries remaining\")\n","results_test_others = [entry for entry in results_test_others if entry['classifier'] is not None]\n","print(f\"Filtered results_test_others: {len(results_test_others)} entries remaining\")\n","results_val_others = [entry for entry in results_val_others if entry['classifier'] is not None]\n","print(f\"Filtered results_val_others: {len(results_val_others)} entries remaining\")"]},{"cell_type":"markdown","metadata":{},"source":["### sorting per val"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["#num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","\n","num_features_range = list(range(1, 30))\n","\n","grid_results_others = {}\n","grid_results_lasso = {}\n","\n","selectors = ['mrmr', 'rf', 'logistic']\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            #print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                    \n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val_others:\n","                        ## qui filtro per num_features\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_others[(classifier, selector, num_features)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","\n","## ORA PER LASSO\n","selectors = ['lasso']\n","for classifier in classifiers:\n","    #print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        #print(f\"Sto iniziando selector {selector}\")\n","        for alpha in alpha_values:\n","                filtered_results = []\n","                for res in results_val_lasso:\n","                    ## qui filtro per alpha\n","                    if (res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha):\n","                        filtered_results.append(res)\n","\n","                if filtered_results:\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n","                        roc_values=[res['roc_auc'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n","                        avg_roc = sum(roc_values) / len(roc_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n","                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_lasso[(classifier, selector, alpha)] = {\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_balaccuracy': avg_balaccuracy,\n","                            'std_balaccuracy': std_balaccuracy,\n","                            'avg_roc_auc': avg_roc,\n","                            'std_roc_auc': std_roc_auc\n","                        }\n","\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']),reverse=True)\n","sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n","\n","#sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']),reverse=True)\n","#sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### sorting solo balanced accuracy totale"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["sorted_results1 = sorted_results_others + sorted_results_lasso\n","\n","def sort_key(x):\n","    result1=round(x[1]['avg_balaccuracy'], 2)\n","    result2=round(x[1]['avg_roc_auc'], 2)\n","    return (result1, result2)\n","\n","sorted_results1 = sorted(sorted_results1, key=sort_key, reverse=True)\n","\n","\n","#sorted_results = sorted(sorted_results, key=lambda x: (round(x[1]['avg_balaccuracy'], 2), round(x[1]['avg_roc_auc'],2)), reverse=True)\n","#sorted_results = sorted(sorted_results, key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### sorting con roc_auc se differenza < 0.002"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["import functools\n","\n","# Funzione di ordinamento personalizzata\n","def compare_items(item1, item2):\n","    balacc1 = item1[1]['avg_balaccuracy']\n","    balacc2 = item2[1]['avg_balaccuracy']\n","    \n","    # Se la differenza tra le balanced accuracies è minore di 0.001, confronta la ROC AUC\n","    if abs(balacc1 - balacc2) < 0.002:\n","        roc_auc1 = item1[1]['avg_roc_auc']\n","        roc_auc2 = item2[1]['avg_roc_auc']\n","        # Confronta la ROC AUC e ritorna -1, 0 o 1 per l'ordinamento\n","        if roc_auc1 > roc_auc2:\n","            return 1\n","        elif roc_auc1 < roc_auc2:\n","            return -1\n","        else:\n","            return 0\n","    else:\n","        # Altrimenti ordina per balanced accuracy\n","        if balacc1 > balacc2:\n","            return 1\n","        elif balacc1 < balacc2:\n","            return -1\n","        else:\n","            return 0\n","\n","# Combina i risultati di others e lasso\n","sorted_results = sorted_results_others + sorted_results_lasso\n","\n","# Utilizza cmp_to_key per usare la funzione di comparazione personalizzata\n","sorted_results = sorted(sorted_results, key=functools.cmp_to_key(compare_items), reverse=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["### mostro migliori combo"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Migliori 2 combinazioni di parametri:\n","\n","#1:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 28\n","Performance medie sul val set: \n","ROC AUC = 0.857746913580247 (std = 0.11657203523779533), Balanced Accuracy = 0.8388888888888889 (std = 0.13879163261504857)\n","Metrics on the TEST set:\n","Selected Features: [12, 7, 15, 42, 41, 43, 24, 33, 39, 35, 1, 20, 29, 13, 10, 11, 31, 25, 34, 4, 21, 22, 40, 36, 28, 14, 16, 0]\n","ROC AUC: 0.6805555555555555\n","F1 Score: 0.5714285714285714\n","Accuracy: 0.6923076923076923\n","Balanced Accuracy: 0.6851851851851851\n","Confusion Matrix: \n","[[19  8]\n"," [ 4  8]]\n","\n","#2:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 27\n","Performance medie sul val set: \n","ROC AUC = 0.8552469135802468 (std = 0.12020797647975916), Balanced Accuracy = 0.8388888888888889 (std = 0.13879163261504857)\n","Metrics on the TEST set:\n","Selected Features: [12, 7, 15, 42, 41, 43, 24, 33, 39, 35, 1, 20, 29, 13, 10, 11, 31, 25, 34, 4, 21, 22, 40, 36, 28, 14, 16]\n","ROC AUC: 0.6743827160493827\n","F1 Score: 0.5714285714285714\n","Accuracy: 0.6923076923076923\n","Balanced Accuracy: 0.6851851851851851\n","Confusion Matrix: \n","[[19  8]\n"," [ 4  8]]\n"]}],"source":["n=2\n","best_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_combinations, start=1):\n","\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","        print(f\"Alpha: {params[2]}\")\n","    else:\n","        print(f\"Num_features: {params[2]}\")\n","\n","    print(f\"Performance medie sul val set: \\nROC AUC = {metrics['avg_roc_auc']} (std = {metrics['std_roc_auc']}), \"f\"Balanced Accuracy = {metrics['avg_balaccuracy']} (std = {metrics['std_balaccuracy']})\")\n","\n","\n","\n","    for p in range (0, len(results_test_others)):\n","            if(params[1]=='lasso'):\n","                if(results_test_lasso[p]['classifier']==params[0] and results_test_lasso[p]['alpha']==params[2]):\n","                        best_case=results_test_lasso[p]\n","                        break\n","            else:     \n","                if(results_test_others[p]['classifier']==params[0] and results_test_others[p]['selector']==params[1] and results_test_others[p]['num_features']==params[2]):\n","                        best_case=results_test_others[p]\n","                        break\n","\n","    \n","    print(\"Metrics on the TEST set:\")\n","\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### salva csv encoder"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Miglior combinazione nel validation set:\n","Classifier: SVM\n","Selector: mrmr\n","Selected Features: [1, 43, 7, 12, 15, 42, 41, 33, 24, 39, 35, 10, 13, 29, 11, 4, 31, 25, 20, 34, 36, 21, 14, 22, 40, 28, 16, 5]\n","Indici delle feature originali selezionate: [ 100 2047  326  717  951 2008 1976 1701 1331 1951 1836  591  847 1600\n","  630  113 1657 1336 1181 1775 1891 1213  874 1275 1969 1596  974  157]\n","Le feature selezionate sono state salvate nel file '/Users/alessiamenozzi/Desktop/selected_features_RESNET.csv'\n"]}],"source":["# File path del dataset originale\n","file_path = \"../CSV/EncodersSliceMaggiore/RESNET50_Slice_Maggiore.csv\"  # O sostituisci con RESNET50\n","\n","# Carica il dataset originale\n","df = pd.read_csv(file_path, sep=',')\n","\n","# Converte 'Unnamed: 0' in intero e ordina secondo i pazienti caricati (se presenti)\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","\n","# Trova la miglior combinazione basata su balanced accuracy nel validation set\n","selected_metric = 'balanced accuracy'\n","best_combination_val = sorted_results[0]\n","params, metrics= best_combination_val\n","\n","selected_features=[]\n","if(params[1]=='lasso'):\n","    for res in results_val_lasso:\n","        if(res['classifier']==params[0] and res['selector']==params[1] and res['alpha']==params[2]):\n","            selected_features=res['selected_features']\n","            print(selected_features)\n","            break\n","else:\n","    for res in results_val_others:\n","        if(res['classifier']==params[0] and res['selector']==params[1] and res['num_features']==params[2]):\n","            selected_features=res['selected_features']\n","            \n","            break\n","\n","# Stampa la miglior combinazione\n","print(\"Miglior combinazione nel validation set:\")\n","print(f\"Classifier: {params[0]}\")\n","print(f\"Selector: {params[1]}\")\n","#print(f\"{selected_metric}: {best_combination_val[selected_metric]}\")\n","print(f\"Selected Features: {selected_features}\")  # Questo contiene gli indici delle feature selezionate\n","\n","# Seleziona gli indici originali delle feature\n","selected_original_features = original_features[selected_features]\n","\n","# Stampa gli indici originali delle feature selezionate\n","print(f\"Indici delle feature originali selezionate: {selected_original_features}\")\n","\n","# Seleziona solo le colonne delle feature originali selezionate dal CSV originale\n","selected_feature_columns = df_features.iloc[:, selected_original_features]\n","\n","# Aggiungi la colonna paziente\n","df_selected = pd.concat([df_ordered[['Unnamed: 0']], selected_feature_columns], axis=1)\n","\n","# Rinomina la colonna 'Unnamed: 0' come 'Paziente'\n","df_selected.rename(columns={'Unnamed: 0': 'Paziente'}, inplace=True)\n","\n","# Salva il CSV con le feature selezionate\n","output_csv_filename = \"/Users/alessiamenozzi/Desktop/selected_features_RESNET.csv\"\n","df_selected.to_csv(output_csv_filename, index=False)\n","\n","print(f\"Le feature selezionate sono state salvate nel file '{output_csv_filename}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### salva csv radiomica"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Miglior combinazione nel validation set:\n","Classifier: RandomForest\n","Selector: mrmr\n","Selected Features: [37, 36, 33, 16, 58, 26, 50, 31, 45, 34, 32, 13, 23, 54, 10, 30, 20, 35, 40, 49, 48, 4]\n","Indici delle feature originali selezionate: [360 353 321 194 473 287 418 308 380 325 311 139 232 467 125 302 218 333\n"," 370 411 395   8]\n","Le feature selezionate sono state salvate nel file '/Users/alessiamenozzi/Desktop/selected_features_radiomica_with_patients.csv'\n"]}],"source":["# File path del dataset originale\n","file_path = \"../CSV/EncodersSliceMaggiore/Radiomica_Wavelet_2D.csv\"\n","\n","# Carica il dataset originale e rimuovi le colonne specificate\n","df = pd.read_csv(file_path, sep=',')\n","\n","# Colonne da rimuovere specifiche per Radiomica\n","columns_to_remove = [\n","    'Slice',\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","# Pulizia del dataset rimuovendo le colonne inutili\n","df_cleaned = df.drop(columns=columns_to_remove)\n","\n","# Estrai le features rimuovendo la colonna 'Paziente'\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","features = df_features.to_numpy()\n","\n","# Trova la miglior combinazione basata su balanced accuracy nel validation set\n","selected_metric = 'balanced accuracy'\n","best_combination_val = sorted_results[0]\n","params, metrics= best_combination_val\n","\n","selected_features=[]\n","if(params[1]=='lasso'):\n","    for res in results_val_lasso:\n","        if(res['classifier']==params[0] and res['selector']==params[1] and res['alpha']==params[2]):\n","            selected_features=res['selected_features']\n","            break\n","else:\n","    for res in results_val_others:\n","        if(res['classifier']==params[0] and res['selector']==params[1] and res['num_features']==params[2]):\n","            selected_features=res['selected_features']\n","            break\n","\n","\n","# Stampa la miglior combinazione\n","print(\"Miglior combinazione nel validation set:\")\n","print(f\"Classifier: {params[0]}\")\n","print(f\"Selector: {params[1]}\")\n","#print(f\"{selected_metric}: {best_combination_val[selected_metric]}\")\n","print(f\"Selected Features: {selected_features}\")  # Questo contiene gli indici delle feature selezionate\n","\n","# Seleziona gli indici originali delle feature\n","selected_original_features = original_features[selected_features]\n","# Stampa gli indici originali delle feature selezionate\n","print(f\"Indici delle feature originali selezionate: {selected_original_features}\")\n","\n","# Seleziona solo le colonne delle feature originali selezionate dal CSV originale\n","selected_feature_columns = df_features.iloc[:, selected_original_features]\n","\n","# Aggiungi la colonna paziente\n","df_selected = pd.concat([df_cleaned[['Paziente']], selected_feature_columns], axis=1)\n","\n","# Salva il CSV con le feature selezionate\n","output_csv_filename = \"/Users/alessiamenozzi/Desktop/selected_features_radiomica_with_patients.csv\"\n","df_selected.to_csv(output_csv_filename, index=False)\n","\n","print(f\"Le feature selezionate sono state salvate nel file '{output_csv_filename}'\")"]},{"cell_type":"markdown","metadata":{},"source":["### salva csv insieme"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["I due CSV sono stati uniti e salvati in '/Users/alessiamenozzi/Desktop/Combinazionefeatures_RadWav_RESNET_CrossVal.csv'\n"]}],"source":["# Percorsi dei due file CSV creati in precedenza\n","csv_vgg19 = \"/Users/alessiamenozzi/Desktop/selected_features_RESNET.csv\"\n","csv_radiomica = \"/Users/alessiamenozzi/Desktop/selected_features_radiomica_with_patients.csv\"\n","\n","# Carica i due CSV\n","df_vgg19 = pd.read_csv(csv_vgg19)\n","df_radiomica = pd.read_csv(csv_radiomica)\n","\n","# Assicurati che i due CSV abbiano una colonna in comune per l'unione (es. 'Paziente')\n","# Unisci i due dataframe sulla colonna 'Paziente'\n","df_combined = pd.merge(df_vgg19, df_radiomica, on='Paziente', suffixes=('_vgg', '_radiomica'))\n","\n","# Salva il dataframe combinato in un nuovo file CSV\n","output_csv_filename = \"/Users/alessiamenozzi/Desktop/Combinazionefeatures_RadWav_RESNET_CrossVal.csv\"\n","df_combined.to_csv(output_csv_filename, index=False)\n","\n","print(f\"I due CSV sono stati uniti e salvati in '{output_csv_filename}'\")"]},{"cell_type":"markdown","metadata":{},"source":["## Allenamento Nuovo TEST"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["def classification_method_united(classifier, x_train, y_train, x_test, y_test):\n","\n","    best_case = None\n","\n","    # Inizializza il classificatore usando la funzione di inizializzazione\n","    classi = classifierinitialization(classifier)\n","    \n","    # Addestra il classificatore\n","    classi.fit(x_train, y_train)\n","\n","    # Calcola le probabilità di predizione per il test set\n","    y_proba_test = classi.predict_proba(x_test)[:, 1]\n","\n","    # Soglia fissa a 0.5\n","    threshold = 0.5\n","    y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","    # Calcola le metriche di classificazione\n","    accuracy = accuracy_score(y_test, y_pred_custom_test)\n","    f1 = f1_score(y_test, y_pred_custom_test)\n","    roc_auc = roc_auc_score(y_test, y_proba_test)\n","    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","    pr_auc = auc(recall, precision)\n","    conf = confusion_matrix(y_test, y_pred_custom_test)\n","    bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n","\n","    # Salva i risultati del miglior caso\n","    best_case = {\n","        'classifier': classifier,\n","        'pr_auc': pr_auc,\n","        'roc_auc': roc_auc,\n","        'f1': f1,\n","        'accuracy': accuracy,\n","        'confusion_matrix': conf,\n","        'best_threshold': threshold,\n","        'balanced_accuracy': bal_acc\n","    }\n","\n","    return best_case"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(63, 32)\n","[0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0\n"," 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0]\n"]}],"source":["file_path = \"/Users/alessiamenozzi/Desktop/Combinazionefeatures_RadWav_INCEPTION_CrossVal.csv\"  # Sostituisci con il tuo percorso del file\n","df = pd.read_csv(file_path)\n","\n","# Droppa la prima colonna\n","X = df.drop(df.columns[0], axis=1)\n","\n","Y_train1, y_test, X_train1, X_test= train_test_split(labels, X, test_size=0.3, shuffle=False)\n","Y_train, y_val, X_train, X_val= train_test_split(Y_train1, X_train1, test_size=0.3, shuffle=True, random_state=3, stratify=Y_train1)\n","\n","print(X_train.shape)\n","print(Y_train)"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Risultati per RandomForest ---\n","Classifier: RandomForest\n","Best F1 Score: 0.6207\n","ROC AUC: 0.7253\n","PR AUC: 0.4071\n","Accuracy: 0.7179\n","Balanced Accuracy: 0.7269\n","Best Threshold: 0.5\n","Confusion Matrix:\n","[[19  8]\n"," [ 3  9]]\n","\n","--- Risultati per RandomForest ---\n","Classifier: ensemble\n","Best F1 Score: 0.7273\n","ROC AUC: 0.8944\n","PR AUC: 0.8693\n","Accuracy: 0.7778\n","Balanced Accuracy: 0.7667\n","Best Threshold: 0.5\n","Confusion Matrix:\n","[[13  2]\n"," [ 4  8]]\n"]}],"source":["classifier_inc = \"ensemble\"\n","classifier_vgg = \"RandomForest\"\n","classifier_res = \"SVM\"\n","classifier_rad = \"RandomForest\"\n","\n","print(f\"\\n--- Risultati per {classifier_rad} ---\")\n","## VAL\n","#results = classification_method_united(classifier_rad, X_train, Y_train, X_val, y_val)\n","## TEST\n","results = classification_method_united(classifier_rad, X_train1, Y_train1, X_test, y_test)\n","    \n","# Stampa tutti i risultati ottenuti\n","print(f\"Classifier: {results['classifier']}\")\n","print(f\"Best F1 Score: {results['f1']:.4f}\")\n","print(f\"ROC AUC: {results['roc_auc']:.4f}\")\n","print(f\"PR AUC: {results['pr_auc']:.4f}\")\n","print(f\"Accuracy: {results['accuracy']:.4f}\")\n","print(f\"Balanced Accuracy: {results['balanced_accuracy']:.4f}\")\n","print(f\"Best Threshold: {results['best_threshold']}\")\n","print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\")\n","\n","print(f\"\\n--- Risultati per {classifier_vgg} ---\")\n","results = classification_method_united(classifier_inc, X_train, Y_train, X_val, y_val)\n","## TEST\n","#results = classification_method_united(classifier_res, X_train1, Y_train1, X_test, y_test)\n","    \n","# Stampa tutti i risultati ottenuti\n","print(f\"Classifier: {results['classifier']}\")\n","print(f\"Best F1 Score: {results['f1']:.4f}\")\n","print(f\"ROC AUC: {results['roc_auc']:.4f}\")\n","print(f\"PR AUC: {results['pr_auc']:.4f}\")\n","print(f\"Accuracy: {results['accuracy']:.4f}\")\n","print(f\"Balanced Accuracy: {results['balanced_accuracy']:.4f}\")\n","print(f\"Best Threshold: {results['best_threshold']}\")\n","print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5686764,"sourceId":9375373,"sourceType":"datasetVersion"},{"datasetId":5686788,"sourceId":9375404,"sourceType":"datasetVersion"},{"datasetId":5687116,"sourceId":9375826,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
