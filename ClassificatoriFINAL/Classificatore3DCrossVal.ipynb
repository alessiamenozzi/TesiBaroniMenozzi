{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import ttest_ind\n",
    "from xgboost import XGBClassifier\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"../CSV/data_rad_clin_DEF.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "labels_column = data['label']\n",
    "labels = labels_column.astype(int).tolist()\n",
    "\n",
    "labels=np.array(labels)\n",
    "\n",
    "# Estrazione dei numeri dai nomi dei pazienti\n",
    "loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n",
    "\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(\"Patient Names: \", loaded_patients )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifica il percorso del file CSV\n",
    "csv_path = '../CSV/Encoders3D/VGG19_3D.csv'  # Sostituisci con il tuo percorso\n",
    "\n",
    "# Carica il CSV in un DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ordina il DataFrame in base alla colonna 'Paziente'\n",
    "df_sorted = df.sort_values(by='Paziente')\n",
    "\n",
    "# Estrai le colonne delle features (escludendo la colonna 'Paziente')\n",
    "df_features = df_sorted.drop(columns=['Paziente'])\n",
    "\n",
    "features= df_features.to_numpy()\n",
    "# Mostra il risultato\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni Varie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Rimozione feature correlation\n",
    "def remove_highly_correlated_features(X, threshold=0.85):\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    upper_triangle = np.triu(corr_matrix, k=1)\n",
    "    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n",
    "    X_reduced = np.delete(X, to_drop, axis=1)\n",
    "    return X_reduced, to_drop\n",
    "\n",
    "## Rimozione features p_value\n",
    "def remove_high_pvalue_features(X, y, alpha=0.05):\n",
    "    selector = SelectKBest(score_func=f_classif, k='all')\n",
    "    selector.fit(X, y)\n",
    "    p_values = selector.pvalues_\n",
    "    features_to_keep = np.where(p_values < alpha)[0]\n",
    "    X_reduced = X[:, features_to_keep]\n",
    "    return X_reduced, features_to_keep\n",
    "\n",
    "## FEATURE SELECTION LASSO\n",
    "def select_features_with_lasso(X, y, alpha=0.001):\n",
    "    \n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    coefficients = lasso.coef_\n",
    "    selected_features = np.where(coefficients != 0)[0]\n",
    "    X_selected = X[:, selected_features]\n",
    "\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FEATURE SELECTION LOGISTIC\n",
    "def logistic_regression_feature_selection(X, y, num_features):\n",
    "    lr = LogisticRegression(max_iter=2000, random_state=42)\n",
    "    lr.fit(X, y)\n",
    "    coef_abs = np.abs(lr.coef_)\n",
    "    feature_importances = np.mean(coef_abs, axis=0)\n",
    "    selected_features = feature_importances.argsort()[-num_features:][::-1]\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FEATURE SELECTION MRMR\n",
    "def mrmr_feature_selection(X, y, num_features):\n",
    "    mi = mutual_info_classif(X, y, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n",
    "    \n",
    "    selected_features = []\n",
    "    selected_indices = []\n",
    "\n",
    "    first_feature_index = np.argmax(mi)\n",
    "    selected_features.append(first_feature_index)\n",
    "    selected_indices.append(first_feature_index)\n",
    "    \n",
    "    for _ in range(num_features - 1):\n",
    "        max_relevance = -np.inf\n",
    "        selected_feature_index = -1\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            if i in selected_indices:\n",
    "                continue\n",
    "            \n",
    "            relevance = mi[i]\n",
    "            redundancy = np.mean(distances[i, selected_indices])\n",
    "            \n",
    "            mrmr_score = relevance - redundancy\n",
    "            \n",
    "            if mrmr_score > max_relevance:\n",
    "                max_relevance = mrmr_score\n",
    "                selected_feature_index = i\n",
    "        \n",
    "        selected_features.append(selected_feature_index)\n",
    "        selected_indices.append(selected_feature_index)\n",
    "\n",
    "    X_selected = X[:, selected_indices]\n",
    "    return X_selected, selected_indices\n",
    "\n",
    "## FEATURE SELECTION RANDOM FOREST\n",
    "def rf_feature_selection(X, y, num_features):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    feature_importances = rf.feature_importances_\n",
    "    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "\n",
    "## FEATURE SELECTION P_VALUE\n",
    "# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n",
    "# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n",
    "\n",
    "def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n",
    "    p_values = []\n",
    "    num_features_total = x_train_expanded.shape[1]\n",
    "\n",
    "    # Calcolo dei p-value per ciascuna feature\n",
    "    for i in range(num_features_total):\n",
    "        feature = x_train_expanded[:, i]\n",
    "        group_0 = feature[y_train_expanded == 0]\n",
    "        group_1 = feature[y_train_expanded == 1]\n",
    "        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n",
    "        p_values.append(p_val)\n",
    "\n",
    "\n",
    "    p_values = np.array(p_values)\n",
    "\n",
    "    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n",
    "    sorted_indices = np.argsort(p_values)\n",
    "    sorted_indices = sorted_indices[:num_features]\n",
    "\n",
    "    x_train_selected = x_train_expanded[:, sorted_indices]\n",
    "\n",
    "    return x_train_selected, sorted_indices\n",
    "\n",
    "\n",
    "\n",
    "## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n",
    "def filter_patients_features(filtered_patients, selected_features):\n",
    "    filtered_patients_selected = []\n",
    "\n",
    "    for patient_features in filtered_patients:\n",
    "        # Select only the features specified in selected_features\n",
    "        patient_features_selected = patient_features[:, selected_features]\n",
    "        filtered_patients_selected.append(patient_features_selected)\n",
    "\n",
    "    return filtered_patients_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classificazione completa che ritorna la threshold migliore per la classificazione\n",
    "def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"selector\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n",
    "    best_f1_score = 0\n",
    "    best_case = None\n",
    "\n",
    "    if mode == \"selector\":\n",
    "        selected_features = None \n",
    "\n",
    "        if num_features != len(x_train_expanded[0]) or alpha != 0:\n",
    "            if selector == \"lasso\":\n",
    "                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n",
    "                if(len(selected_features)==0):\n",
    "                    return 0\n",
    "            elif selector == \"logistic\":\n",
    "                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"mrmr\":\n",
    "                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"rf\":\n",
    "                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"p_value\":\n",
    "                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n",
    "            else:\n",
    "                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n",
    "                return\n",
    "\n",
    "            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n",
    "\n",
    "        number_features = len(selected_features)  # Numero di feature selezionate\n",
    "        #print(\"Ho scelto le features: \", selected_features)\n",
    "\n",
    "        # Training del classificatore\n",
    "        classifier.fit(X_selected, y_train_expanded)\n",
    "\n",
    "    elif mode == \"features\":  # Non fa feature selection ma usa le selected_features passate\n",
    "        if selected_features is None or len(selected_features) == 0:\n",
    "            print(\"Error: selected_features must be provided in 'features' mode.\")\n",
    "            return\n",
    "        \n",
    "        #print(\"Testo sulle features:  \", selected_features)\n",
    "        # Usa solo le selected features su train e test\n",
    "        X_selected = x_train_expanded[:, selected_features]\n",
    "        x_test = x_test[:, selected_features]\n",
    "\n",
    "        number_features = len(selected_features)\n",
    "\n",
    "        # Training del classificatore su train + validation\n",
    "        classifier.fit(X_selected, y_train_expanded)\n",
    "    \n",
    "    else:\n",
    "           print(\"Errore, scegliere tra: selector / features\")\n",
    "\n",
    "    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n",
    "        thresholds=[thresholds]\n",
    "        \n",
    "    \n",
    "    for threshold in thresholds:\n",
    "\n",
    "            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred_custom_test)\n",
    "            f1 = f1_score(y_test, y_pred_custom_test)\n",
    "            roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "            pr_auc = auc(recall, precision)\n",
    "\n",
    "            conf = confusion_matrix(y_test, y_pred_custom_test)\n",
    "            \n",
    "            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n",
    "\n",
    "\n",
    "            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n",
    "            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n",
    "                best_f1_score = f1\n",
    "                best_case = {\n",
    "                    'alpha': alpha,\n",
    "                    'num_features': number_features,\n",
    "                    'selected_features': selected_features,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'f1': f1,\n",
    "                    'accuracy': accuracy,\n",
    "                    'confusion_matrix': conf,\n",
    "                    'best_threshold': threshold,\n",
    "                    'balanced accuracy': bal_acc\n",
    "                }\n",
    "\n",
    "    return best_case\n",
    "\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "### questo ritorna le il vettore di probabilità senza fare la classificazione\n",
    "def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n",
    "\n",
    "    if mode == \"Val\":\n",
    "        selected_features = None \n",
    "\n",
    "        if num_features != len(x_train_expanded[0]) or alpha != 0:\n",
    "            if selector == \"lasso\":\n",
    "                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n",
    "                if (len(selected_features)==0):\n",
    "                    return [0],0,[0]\n",
    "            elif selector == \"logistic\":\n",
    "                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"mrmr\":\n",
    "                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"rf\":\n",
    "                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"p_value\":\n",
    "                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n",
    "            else:\n",
    "                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n",
    "                return\n",
    "\n",
    "            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n",
    "        else:\n",
    "            X_selected = x_train_expanded\n",
    "            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n",
    "\n",
    "        number_features = len(selected_features)  # Numero di feature selezionate\n",
    "\n",
    "        # Training del classificatore\n",
    "        classifier.fit(X_selected, y_train_expanded)\n",
    "\n",
    "\n",
    "    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n",
    "        x_test = x_test[:, selected_features]\n",
    "        number_features = len(selected_features)\n",
    "    \n",
    "\n",
    "    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    " \n",
    "    return y_proba_test, number_features, selected_features\n",
    "\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "\n",
    "### classificazione effettuata con una threshold specifica\n",
    "def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n",
    "        \n",
    "            best_case = None\n",
    "\n",
    "            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n",
    "            accuracy = accuracy_score(y_test, y_pred_custom_test)\n",
    "            f1 = f1_score(y_test, y_pred_custom_test)\n",
    "            roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            bal_acc = balanced_accuracy_score(y_test, y_pred_custom_test)\n",
    "\n",
    "            conf = confusion_matrix(y_test, y_pred_custom_test)\n",
    "            best_case = {\n",
    "                    'alpha': alpha,\n",
    "                    'num_features': number_features,\n",
    "                    'selected_features': selected_features,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'f1': f1,\n",
    "                    'accuracy': accuracy,\n",
    "                    'confusion_matrix': conf,\n",
    "                    'threshold': threshold,\n",
    "                    'balanced accuracy': bal_acc\n",
    "                }\n",
    "                \n",
    "            if not best_case:\n",
    "                 print(\"Attenzione caso vuoto\") \n",
    "            return best_case\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "\n",
    "# metodo che definisce la threshold ottimale attraverso Youden's J statistic (threshold_selection= 'y')\n",
    "# oppure attraverso la distanza euclidea dalla curva ROC (threshold_selection= 'd')\n",
    "def classification_method_selection(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, threshold_selection, mode=\"Val\", selected_features=[0]):\n",
    "    best_case = None\n",
    "\n",
    "    if mode == \"Val\":\n",
    "        selected_features = None \n",
    "\n",
    "        if num_features != len(x_train_expanded[0]) or alpha != 0:\n",
    "            if selector == \"lasso\":\n",
    "                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n",
    "                if(len(selected_features)==0):\n",
    "                    return 0\n",
    "            elif selector == \"logistic\":\n",
    "                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"mrmr\":\n",
    "                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"rf\":\n",
    "                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"p_value\":\n",
    "                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n",
    "            else:\n",
    "                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n",
    "                return\n",
    "\n",
    "            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n",
    "        else:\n",
    "            X_selected = x_train_expanded\n",
    "            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n",
    "\n",
    "        number_features = len(selected_features)  # Numero di feature selezionate\n",
    "\n",
    "        classi=classifierinitialization(classifier, X_selected, y_train_expanded )\n",
    "        # Training del classificatore\n",
    "        classi.fit(X_selected, y_train_expanded)\n",
    "\n",
    "\n",
    "    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n",
    "        x_test = x_test[:, selected_features]\n",
    "        number_features = len(selected_features)\n",
    "    \n",
    "\n",
    "    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "    pr_auc = auc(recall, precision)\n",
    "        \n",
    "    fpr,tpr,threshold=roc_curve(y_test,y_proba_test,pos_label=1)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_threshold = threshold[np.argmax(youden_j)]\n",
    "\n",
    "    ## due modalità \n",
    "    if threshold_selection == 'y':\n",
    "        youden_j = tpr - fpr\n",
    "        optimal_threshold = threshold[np.argmax(youden_j)]\n",
    "    elif threshold_selection == 'd':\n",
    "        distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n",
    "        optimal_threshold = threshold[np.argmin(distances)]\n",
    "    else:\n",
    "        print('Threshold non valida!')\n",
    "        return None\n",
    "\n",
    "    \n",
    "    y_pred_custom_test = (y_proba_test >= optimal_threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_custom_test)\n",
    "    f1 = f1_score(y_test, y_pred_custom_test)\n",
    "    conf = confusion_matrix(y_test, y_pred_custom_test)\n",
    "\n",
    "\n",
    "    best_case = {\n",
    "        'alpha': alpha,\n",
    "        'num_features': number_features,\n",
    "        'selected_features': selected_features,\n",
    "        'pr_auc': pr_auc,\n",
    "        'roc_auc': roc_auc,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf,\n",
    "        'best_threshold': optimal_threshold,\n",
    "        'threshold_mode': threshold_selection\n",
    "    }\n",
    "\n",
    "    return best_case\n",
    "\n",
    "def classifierinitialization(classifier):\n",
    "    if classifier == 'RandomForest':\n",
    "                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif classifier == 'Logistic':\n",
    "                            classi = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    elif classifier == 'SVM':\n",
    "                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    elif classifier == 'XgBoost':\n",
    "                            classi = XGBClassifier(random_state=42)\n",
    "    elif classifier == 'MLP':\n",
    "                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation = 'logistic')\n",
    "    elif classifier == 'ensemble':\n",
    "                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                            logistic_model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "                            classi = VotingClassifier(\n",
    "                                estimators=[\n",
    "                                    ('random_forest', rf_model),\n",
    "                                    ('logistic', logistic_model),\n",
    "                                    ('svc', svc_model)\n",
    "                                ],\n",
    "                                voting='soft'\n",
    "                                )\n",
    "    return classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split e correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"Number of train patients: \", len(X_train))\n",
    "print(\"Number of test patients: \", len(y_test))\n",
    "\n",
    "print(\"Number of features for every image: \", X_train[0].shape[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## FEATURE CORRELATION\n",
    "\n",
    "X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.8)\n",
    "X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n",
    "\n",
    "\n",
    "print(X_train_reduced.shape)\n",
    "print(X_test_reduced.shape)\n",
    "\n",
    "\n",
    "# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n",
    "\n",
    "X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, Y_train, alpha=0.01)\n",
    "X_test_reduced = X_test_reduced[:, features_to_keep]\n",
    "\n",
    "print(X_train_reduced.shape)\n",
    "print(X_test_reduced.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametri iniziali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_res_inc = np.linspace(0.01, 0.6, 30).tolist() ## RANGE PER RESNET e INCEPETION\n",
    "\n",
    "alpha_vgg = np.linspace(0.005, 0.5, 30).tolist() ## RANGE PER VGG\n",
    "\n",
    "alpha_rad = np.linspace(0.001, 0.05, 30).tolist() ## range per radiomica\n",
    "\n",
    "\n",
    "alpha_values=alpha_res_inc\n",
    "#alpha_values.remove(0.0)\n",
    "\n",
    "\n",
    "#thresholds=np.arange(0.4, 0.61, 0.01) \n",
    "\n",
    "thresholds=[0.5]\n",
    "\n",
    "#selectors=['lasso', 'mrmr','rf', 'logistic']\n",
    "\n",
    "classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n",
    "#classifiers=['SVM', 'ensemble','RandomForest', 'Logistic']\n",
    "selectors=['mrmr','rf', 'logistic', 'lasso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template_dict = {\n",
    "                'fold': None,\n",
    "                'classifier': None,\n",
    "                'selector': None,\n",
    "                'alpha': None,\n",
    "                'num_features': None,\n",
    "                'pr_auc': None,\n",
    "                'roc_auc': None,\n",
    "                'f1': None,\n",
    "                'accuracy': None,\n",
    "                'confusion_matrix': [],\n",
    "                'selected_features': [],\n",
    "                'balanced accuracy': None\n",
    "            }\n",
    "\n",
    "\n",
    "results_val_others = [template_dict.copy() for _ in range(5000)]\n",
    "results_val_others.append(template_dict.copy())\n",
    "\n",
    "results_val_lasso = [template_dict.copy() for _ in range(5000)]\n",
    "results_val_lasso.append(template_dict.copy())\n",
    "\n",
    "results_test_others = [template_dict.copy() for _ in range(5000)]\n",
    "results_test_others.append(template_dict.copy())\n",
    "\n",
    "results_test_lasso = [template_dict.copy() for _ in range(5000)]\n",
    "results_test_lasso.append(template_dict.copy())\n",
    "limit=30\n",
    "\n",
    "smote = SMOTE(random_state=10)\n",
    " \n",
    "k=0\n",
    "u=0\n",
    "n_folds=5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selezione con selector e num features fissi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n",
    "    print(\"Starting with fold:\", fold_idx)\n",
    "\n",
    "    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n",
    "    y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "    x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n",
    "\n",
    "    #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n",
    "\n",
    "\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "            print(\"Starting with classifier:\", classifier)\n",
    "            for j, selector in enumerate(selectors):\n",
    "                print(\"Starting with selector:\", selector)\n",
    "\n",
    "                if(selector=='lasso'):\n",
    "\n",
    "                    for alpha in alpha_values:\n",
    "                        #print(\"Doing alpha \", alpha )\n",
    "                        classi= classifierinitialization(classifier)\n",
    "                        best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "                        \n",
    "                        if(best_case_val==0):\n",
    "                            continue\n",
    "                        if(best_case_val['num_features']> limit):\n",
    "                             continue\n",
    "                        \n",
    "                        results_val_lasso[k] = {\n",
    "                                            'fold': fold_idx,\n",
    "                                            'classifier': classifier,\n",
    "                                            'selector': selector,\n",
    "                                            'alpha': alpha,\n",
    "                                            'num_features': best_case_val['num_features'],\n",
    "                                            'selected_features': best_case_val['selected_features'],\n",
    "                                            'pr_auc': best_case_val['pr_auc'],\n",
    "                                            'roc_auc': best_case_val['roc_auc'],\n",
    "                                            'f1': best_case_val['f1'],\n",
    "                                            'accuracy': best_case_val['accuracy'],\n",
    "                                            'confusion_matrix': best_case_val['confusion_matrix'],\n",
    "                                            'balanced accuracy': best_case_val['balanced accuracy'],\n",
    "                                            }\n",
    "\n",
    "                        #print(best_case_val['num_features'])\n",
    "                        \n",
    "\n",
    "                        if(fold_idx==0):\n",
    "                            classi= classifierinitialization(classifier)\n",
    "                            best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "\n",
    "                            if(best_case_test==0):\n",
    "                                continue\n",
    "                            \n",
    "                            results_test_lasso[u] = {\n",
    "                                                'classifier': classifier,\n",
    "                                                'selector': selector,\n",
    "                                                'alpha': alpha,\n",
    "                                                'num_features': best_case_test['num_features'],\n",
    "                                                'selected_features': best_case_test['selected_features'],\n",
    "                                                'pr_auc': best_case_test['pr_auc'],\n",
    "                                                'roc_auc': best_case_test['roc_auc'],\n",
    "                                                'f1': best_case_test['f1'],\n",
    "                                                'accuracy': best_case_test['accuracy'],\n",
    "                                                'confusion_matrix': best_case_test['confusion_matrix'],\n",
    "                                                'balanced accuracy': best_case_test['balanced accuracy'],\n",
    "                                                }\n",
    "                            u=u+1\n",
    "                        k = k + 1\n",
    "\n",
    "                else:\n",
    "                    #limit=len(x_train_reduced[0]) + 1\n",
    "                    limit=30\n",
    "                    for t in range(1, limit):\n",
    "                            classi= classifierinitialization(classifier)\n",
    "\n",
    "                            best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "                    \n",
    "                                \n",
    "                            results_val_others[k] = {\n",
    "                                                'fold': fold_idx,\n",
    "                                                'classifier': classifier,\n",
    "                                                'selector': selector,\n",
    "                                                'alpha': 0,\n",
    "                                                'num_features': t,\n",
    "                                                'selected_features': best_case_val['selected_features'],\n",
    "                                                'pr_auc': best_case_val['pr_auc'],\n",
    "                                                'roc_auc': best_case_val['roc_auc'],\n",
    "                                                'f1': best_case_val['f1'],\n",
    "                                                'accuracy': best_case_val['accuracy'],\n",
    "                                                'confusion_matrix': best_case_val['confusion_matrix'],\n",
    "                                                'balanced accuracy': best_case_val['balanced accuracy'],\n",
    "                                                }\n",
    "                            #print(results_val_others[k]['f1'])\n",
    "\n",
    "                            if(fold_idx==0):\n",
    "                                classi= classifierinitialization(classifier)\n",
    "                                best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "                                \n",
    "                                results_test_others[u] = {\n",
    "                                                    'classifier': classifier,\n",
    "                                                    'selector': selector,\n",
    "                                                    'alpha': 0,\n",
    "                                                    'num_features': t,\n",
    "                                                    'selected_features': best_case_test['selected_features'],\n",
    "                                                    'pr_auc': best_case_test['pr_auc'],\n",
    "                                                    'roc_auc': best_case_test['roc_auc'],\n",
    "                                                    'f1': best_case_test['f1'],\n",
    "                                                    'accuracy': best_case_test['accuracy'],\n",
    "                                                    'confusion_matrix': best_case_test['confusion_matrix'],\n",
    "                                                    'balanced accuracy': best_case_test['balanced accuracy'],\n",
    "                                                    }\n",
    "                                u=u+1\n",
    "\n",
    "                            k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selezione con features fisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n",
    "    print(\"Starting with fold:\", fold_idx)\n",
    "\n",
    "    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n",
    "    y_train, y_val = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "    x_train_reduced, y_train = smote.fit_resample(x_train_reduced, y_train)\n",
    "\n",
    "    #X_train_reduced, Y_train = smote.fit_resample(X_train_reduced, Y_train)\n",
    "\n",
    "\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "            print(\"Starting with classifier:\", classifier)\n",
    "            for j, selector in enumerate(selectors):\n",
    "                print(\"Starting with selector:\", selector)\n",
    "\n",
    "                if(selector=='lasso'):\n",
    "\n",
    "                    for alpha in alpha_values:\n",
    "                        #print(\"Doing alpha \", alpha )\n",
    "                        classi= classifierinitialization(classifier)\n",
    "                        best_case_val= classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, 0, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "                        \n",
    "                        if(best_case_val==0):\n",
    "                            continue\n",
    "                        if(best_case_val['num_features']> limit):\n",
    "                             continue\n",
    "                        \n",
    "                        results_val_lasso[k] = {\n",
    "                                            'fold': fold_idx,\n",
    "                                            'classifier': classifier,\n",
    "                                            'selector': selector,\n",
    "                                            'alpha': alpha,\n",
    "                                            'num_features': best_case_val['num_features'],\n",
    "                                            'selected_features': best_case_val['selected_features'],\n",
    "                                            'pr_auc': best_case_val['pr_auc'],\n",
    "                                            'roc_auc': best_case_val['roc_auc'],\n",
    "                                            'f1': best_case_val['f1'],\n",
    "                                            'accuracy': best_case_val['accuracy'],\n",
    "                                            'confusion_matrix': best_case_val['confusion_matrix'],\n",
    "                                            'balanced accuracy': best_case_val['balanced accuracy'],\n",
    "                                            }\n",
    "\n",
    "                        #print(best_case_val['num_features'])\n",
    "                        \n",
    "\n",
    "                        if(fold_idx==0):\n",
    "                            classi= classifierinitialization(classifier)\n",
    "                            best_case_test= classification_method(selector, classi, alpha, X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"features\", selected_features=best_case_val['selected_features'], thresholds=0.5)\n",
    "\n",
    "                            if(best_case_test==0):\n",
    "                                continue\n",
    "                            \n",
    "                            results_test_lasso[u] = {\n",
    "                                                'classifier': classifier,\n",
    "                                                'selector': selector,\n",
    "                                                'alpha': alpha,\n",
    "                                                'num_features': best_case_test['num_features'],\n",
    "                                                'selected_features': best_case_test['selected_features'],\n",
    "                                                'pr_auc': best_case_test['pr_auc'],\n",
    "                                                'roc_auc': best_case_test['roc_auc'],\n",
    "                                                'f1': best_case_test['f1'],\n",
    "                                                'accuracy': best_case_test['accuracy'],\n",
    "                                                'confusion_matrix': best_case_test['confusion_matrix'],\n",
    "                                                'balanced accuracy': best_case_test['balanced accuracy'],\n",
    "                                                }\n",
    "                            u=u+1\n",
    "                        k = k + 1\n",
    "\n",
    "                else:\n",
    "                    #limit=len(x_train_reduced[0]) + 1\n",
    "                    limit=30\n",
    "                    for t in range(1, limit):\n",
    "                            classi= classifierinitialization(classifier)\n",
    "\n",
    "                            best_case_val= classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, t, mode=\"selector\", selected_features=[0], thresholds=0.5)\n",
    "                    \n",
    "                                \n",
    "                            results_val_others[k] = {\n",
    "                                                'fold': fold_idx,\n",
    "                                                'classifier': classifier,\n",
    "                                                'selector': selector,\n",
    "                                                'alpha': 0,\n",
    "                                                'num_features': t,\n",
    "                                                'selected_features': best_case_val['selected_features'],\n",
    "                                                'pr_auc': best_case_val['pr_auc'],\n",
    "                                                'roc_auc': best_case_val['roc_auc'],\n",
    "                                                'f1': best_case_val['f1'],\n",
    "                                                'accuracy': best_case_val['accuracy'],\n",
    "                                                'confusion_matrix': best_case_val['confusion_matrix'],\n",
    "                                                'balanced accuracy': best_case_val['balanced accuracy'],\n",
    "                                                }\n",
    "                            #print(results_val_others[k]['f1'])\n",
    "\n",
    "                            if(fold_idx==0):\n",
    "                                classi= classifierinitialization(classifier)\n",
    "                                best_case_test= classification_method(selector, classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, t, mode=\"features\", selected_features=best_case_val['selected_features'], thresholds=0.5)\n",
    "                                \n",
    "                                results_test_others[u] = {\n",
    "                                                    'classifier': classifier,\n",
    "                                                    'selector': selector,\n",
    "                                                    'alpha': 0,\n",
    "                                                    'num_features': t,\n",
    "                                                    'selected_features': best_case_test['selected_features'],\n",
    "                                                    'pr_auc': best_case_test['pr_auc'],\n",
    "                                                    'roc_auc': best_case_test['roc_auc'],\n",
    "                                                    'f1': best_case_test['f1'],\n",
    "                                                    'accuracy': best_case_test['accuracy'],\n",
    "                                                    'confusion_matrix': best_case_test['confusion_matrix'],\n",
    "                                                    'balanced accuracy': best_case_test['balanced accuracy'],\n",
    "                                                    }\n",
    "                                u=u+1\n",
    "\n",
    "                            k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminazione dizionari vuoti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test_lasso = [entry for entry in results_test_lasso if entry['classifier'] is not None]\n",
    "print(f\"Filtered results_test_lasso: {len(results_test_lasso)} entries remaining\")\n",
    "results_val_lasso= [entry for entry in results_val_lasso if entry['classifier'] is not None]\n",
    "print(f\"Filtered results_val_lasso: {len(results_val_lasso)} entries remaining\")\n",
    "results_test_others = [entry for entry in results_test_others if entry['classifier'] is not None]\n",
    "print(f\"Filtered results_test_others: {len(results_test_others)} entries remaining\")\n",
    "results_val_others = [entry for entry in results_val_others if entry['classifier'] is not None]\n",
    "print(f\"Filtered results_val_others: {len(results_val_others)} entries remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting per val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n",
    "\n",
    "num_features_range = list(range(1, 30))\n",
    "\n",
    "grid_results_others = {}\n",
    "grid_results_lasso = {}\n",
    "\n",
    "selectors = ['mrmr', 'rf', 'logistic']\n",
    "\n",
    "# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n",
    "for classifier in classifiers:\n",
    "    #print(f\"Sto iniziando classifier {classifier}\")\n",
    "    for selector in selectors:\n",
    "            #print(f\"Sto iniziando selector {selector}\")\n",
    "            for num_features in num_features_range:\n",
    "                    \n",
    "                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n",
    "                    filtered_results=[]\n",
    "                    for res in results_val_others:\n",
    "                        ## qui filtro per num_features\n",
    "                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n",
    "                            filtered_results.append(res)\n",
    "                \n",
    "                    if filtered_results:\n",
    "                        f1_values = [res['f1'] for res in filtered_results]\n",
    "                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n",
    "                        roc_values=[res['roc_auc'] for res in filtered_results]\n",
    "\n",
    "                        # Calcola le medie delle metriche\n",
    "                        avg_f1 = sum(f1_values) / len(f1_values)\n",
    "                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n",
    "                        avg_roc = sum(roc_values) / len(roc_values)\n",
    "\n",
    "                        # Calcola la deviazione standard delle metriche\n",
    "                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n",
    "                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n",
    "                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n",
    "\n",
    "                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n",
    "                        grid_results_others[(classifier, selector, num_features)] = {\n",
    "                            'avg_f1': avg_f1,\n",
    "                            'std_f1': std_f1,\n",
    "                            'avg_balaccuracy': avg_balaccuracy,\n",
    "                            'std_balaccuracy': std_balaccuracy,\n",
    "                            'avg_roc_auc': avg_roc,\n",
    "                            'std_roc_auc': std_roc_auc\n",
    "                        }\n",
    "\n",
    "\n",
    "\n",
    "## ORA PER LASSO\n",
    "selectors = ['lasso']\n",
    "for classifier in classifiers:\n",
    "    #print(f\"Sto iniziando classifier {classifier}\")\n",
    "    for selector in selectors:\n",
    "        #print(f\"Sto iniziando selector {selector}\")\n",
    "        for alpha in alpha_values:\n",
    "                filtered_results = []\n",
    "                for res in results_val_lasso:\n",
    "                    ## qui filtro per alpha\n",
    "                    if (res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha):\n",
    "                        filtered_results.append(res)\n",
    "\n",
    "                if filtered_results:\n",
    "                        f1_values = [res['f1'] for res in filtered_results]\n",
    "                        balaccuracy_values = [res['balanced accuracy'] for res in filtered_results]\n",
    "                        roc_values=[res['roc_auc'] for res in filtered_results]\n",
    "\n",
    "                        # Calcola le medie delle metriche\n",
    "                        avg_f1 = sum(f1_values) / len(f1_values)\n",
    "                        avg_balaccuracy = sum(balaccuracy_values) / len(balaccuracy_values)\n",
    "                        avg_roc = sum(roc_values) / len(roc_values)\n",
    "\n",
    "                        # Calcola la deviazione standard delle metriche\n",
    "                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n",
    "                        std_balaccuracy = statistics.stdev(balaccuracy_values) if len(balaccuracy_values) > 1 else 0\n",
    "                        std_roc_auc = statistics.stdev(roc_values) if len(roc_values) > 1 else 0\n",
    "\n",
    "                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n",
    "                        grid_results_lasso[(classifier, selector, alpha)] = {\n",
    "                            'avg_f1': avg_f1,\n",
    "                            'std_f1': std_f1,\n",
    "                            'avg_balaccuracy': avg_balaccuracy,\n",
    "                            'std_balaccuracy': std_balaccuracy,\n",
    "                            'avg_roc_auc': avg_roc,\n",
    "                            'std_roc_auc': std_roc_auc\n",
    "                        }\n",
    "\n",
    "\n",
    "# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n",
    "sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']),reverse=True)\n",
    "sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_balaccuracy'], x[1]['avg_roc_auc']), reverse=True)\n",
    "\n",
    "#sorted_results_others = sorted(grid_results_others.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']),reverse=True)\n",
    "#sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_balaccuracy']), reverse=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# Funzione di ordinamento personalizzata\n",
    "def compare_items(item1, item2):\n",
    "    balacc1 = item1[1]['avg_balaccuracy']\n",
    "    balacc2 = item2[1]['avg_balaccuracy']\n",
    "    \n",
    "    # Se la differenza tra le balanced accuracies è minore di 0.001, confronta la ROC AUC\n",
    "    if abs(balacc1 - balacc2) < 0.002:\n",
    "        roc_auc1 = item1[1]['avg_roc_auc']\n",
    "        roc_auc2 = item2[1]['avg_roc_auc']\n",
    "        # Confronta la ROC AUC e ritorna -1, 0 o 1 per l'ordinamento\n",
    "        if roc_auc1 > roc_auc2:\n",
    "            return 1\n",
    "        elif roc_auc1 < roc_auc2:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        # Altrimenti ordina per balanced accuracy\n",
    "        if balacc1 > balacc2:\n",
    "            return 1\n",
    "        elif balacc1 < balacc2:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Combina i risultati di others e lasso\n",
    "sorted_results = sorted_results_others + sorted_results_lasso\n",
    "\n",
    "# Utilizza cmp_to_key per usare la funzione di comparazione personalizzata\n",
    "sorted_results = sorted(sorted_results, key=functools.cmp_to_key(compare_items), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinazione migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "best_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n",
    "\n",
    "print(f\"Migliori {n} combinazioni di parametri:\")\n",
    "for i, (params, metrics) in enumerate(best_combinations, start=1):\n",
    "\n",
    "    print(f\"\\n#{i}:\")\n",
    "    print(f\"Classifier: {params[0]}\")\n",
    "    print(f\"Selector: {params[1]}\")\n",
    "    if (params[1]=='lasso'):\n",
    "        print(f\"Alpha: {params[2]}\")\n",
    "    else:\n",
    "        print(f\"Num_features: {params[2]}\")\n",
    "\n",
    "    print(f\"Performance medie sul val set: \\nROC AUC = {metrics['avg_roc_auc']} (std = {metrics['std_roc_auc']}), \"f\"Balanced Accuracy = {metrics['avg_balaccuracy']} (std = {metrics['std_balaccuracy']})\")\n",
    "\n",
    "\n",
    "\n",
    "    for p in range (0, len(results_test_others)):\n",
    "            if(params[1]=='lasso'):\n",
    "                if(results_test_lasso[p]['classifier']==params[0] and results_test_lasso[p]['alpha']==params[2]):\n",
    "                        best_case=results_test_lasso[p]\n",
    "                        break\n",
    "            else:     \n",
    "                if(results_test_others[p]['classifier']==params[0] and results_test_others[p]['selector']==params[1] and results_test_others[p]['num_features']==params[2]):\n",
    "                        best_case=results_test_others[p]\n",
    "                        break\n",
    "\n",
    "    \n",
    "    print(\"Metrics on the TEST set:\")\n",
    "\n",
    "    print(f\"Selected Features: {best_case['selected_features']}\")\n",
    "    print(f\"ROC AUC: {best_case['roc_auc']}\")\n",
    "    print(f\"F1 Score: {best_case['f1']}\")\n",
    "    print(f\"Accuracy: {best_case['accuracy']}\")\n",
    "    print(f\"Balanced Accuracy: {best_case['balanced accuracy']}\")\n",
    "    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
