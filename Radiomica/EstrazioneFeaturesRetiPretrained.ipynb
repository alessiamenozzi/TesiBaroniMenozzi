{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estrazione features da reti pretrainate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "import nrrd\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singola Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "model = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "pathdicom = \"\\\\Users\\\\bsbar\\\\Desktop\\\\pazienti_nrrd\"\n",
    "pathroi = \"\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ROI\"\n",
    "\n",
    "# funzione per creazione maschera\n",
    "def maskcroppingbox(images_array):\n",
    "    images_array_2 = np.argwhere(images_array)\n",
    "    \n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = images_array_2.min(axis=0), images_array_2.max(axis=0) + 1\n",
    "    return (zstart, ystart, xstart), (zstop, ystop, xstop)\n",
    "        \n",
    "def featureextraction(image_array,mask_array):\n",
    "    # ridimensionamento\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = maskcroppingbox(mask_array)\n",
    "    roi_images = image_array[zstart-1:zstop+1,ystart:ystop,xstart:xstop].transpose((2,1,0))\n",
    "    roi_images1 = zoom(roi_images, zoom=[224/roi_images.shape[0], 224/roi_images.shape[1],1], order=3)\n",
    "    roi_images2 = np.array(roi_images1,dtype=float)    \n",
    "\n",
    "    # Trova la slice più grossa (basato sui pixel attivi della maschera)\n",
    "    slice_sums = np.sum(mask_array[zstart-1:zstop+1, ystart:ystop, xstart:xstop], axis=(1, 2))  # Somma dei pixel per slice\n",
    "    largest_slice_index = np.argmax(slice_sums)  # Indice della slice con il massimo numero di pixel attivi\n",
    "\n",
    "    # Estrai solo la slice più grossa\n",
    "    largest_slice_image = roi_images2[:, :, largest_slice_index]\n",
    "\n",
    "    print(largest_slice_image.shape)\n",
    "\n",
    "    # preprocessing per resnet\n",
    "    x = image.img_to_array(largest_slice_image)\n",
    "    print(x.shape)\n",
    "    x = np.repeat(x, 3, axis=-1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(x.shape)\n",
    "    x = preprocess_input(x)\n",
    "    #x = np.transpose(x, (3, 1, 2, 0))\n",
    "    \n",
    "\n",
    "    # estrazione features principali come feature map\n",
    "    base_model_pool_features = model.predict(x)\n",
    "\n",
    "    feature_map = base_model_pool_features[0]\n",
    "\n",
    "    #print(feature_map)\n",
    "\n",
    "    feature_map = feature_map.transpose((2,1,0))\n",
    "    features = np.max(feature_map,-1)\n",
    "    features = np.max(features,-1)\n",
    "    deeplearningfeatures = collections.OrderedDict()\n",
    "    for ind_,f_ in enumerate(features):\n",
    "    \tdeeplearningfeatures[str(ind_)] = f_\n",
    "         \n",
    "    return deeplearningfeatures\n",
    "\n",
    "\n",
    "# salvataggio features in un file\n",
    "featureDict = {}\n",
    "for s in os.listdir(pathdicom):\n",
    "    print(s)\n",
    "    filename = os.path.join(pathdicom, s)\n",
    "\n",
    "        \n",
    "    for t in os.listdir(filename):\n",
    "\n",
    "        pathdicomnew = os.path.join(pathdicom, s, t)\n",
    "        readdatadicom, header = nrrd.read(pathdicomnew, index_order='C')\n",
    "\n",
    "    pathroinew = os.path.join(pathroi, s)\n",
    "    for g in os.listdir(pathroinew):\n",
    "\n",
    "        troi = os.path.join(pathroi, s, g)\n",
    "        readdatanrrd, header2 = nrrd.read(troi, index_order='C')\n",
    "\n",
    "    \n",
    "    deeplearningfeatures = featureextraction(readdatadicom,readdatanrrd) \n",
    "\n",
    "    result = deeplearningfeatures\n",
    "    key = list(result.keys())\n",
    "    key = key[0:]\n",
    "        \n",
    "    feature = []\n",
    "    for jind in range(len(key)):\n",
    "        feature.append(result[key[jind]])\n",
    "        \n",
    "    featureDict[s] = feature\n",
    "    dictkey = key\n",
    "    print(s)\n",
    "    \n",
    "dataframe = pd.DataFrame.from_dict(featureDict, orient='index', columns=dictkey)\n",
    "dataframe.to_csv('C:\\\\Users\\\\bsbar\\\\Desktop\\\\VGG19_NUOVO.csv')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "(7, 7, 2048)\n",
      "(2048, 7, 7)\n",
      "(2048, 7)\n",
      "(2048,)\n",
      "101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m     readdatanrrd, header2 \u001b[38;5;241m=\u001b[39m nrrd\u001b[38;5;241m.\u001b[39mread(troi, index_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Estrai tutte le features per tutte le slice\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m patient_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeatureextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreaddatadicom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreaddatanrrd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Aggiungi le feature di tutte le slice per questo paziente\u001b[39;00m\n\u001b[0;32m     83\u001b[0m all_feature_dicts\u001b[38;5;241m.\u001b[39mextend(patient_features)\n",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m, in \u001b[0;36mfeatureextraction\u001b[1;34m(image_array, mask_array, patient_id)\u001b[0m\n\u001b[0;32m     18\u001b[0m (zstart, ystart, xstart), (zstop, ystop, xstop) \u001b[38;5;241m=\u001b[39m maskcroppingbox(mask_array)\n\u001b[0;32m     19\u001b[0m roi_images \u001b[38;5;241m=\u001b[39m image_array[zstart\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:zstop\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, ystart:ystop, xstart:xstop]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 20\u001b[0m roi_images1 \u001b[38;5;241m=\u001b[39m \u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mroi_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mroi_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m roi_images2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(roi_images1, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Prepara tutte le slice come un batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:819\u001b[0m, in \u001b[0;36mzoom\u001b[1;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[0;32m    815\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[0;32m    816\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m    817\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    818\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[1;32m--> 819\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "pathdicom = \"\\\\Users\\\\bsbar\\\\Desktop\\\\pazienti_nrrd\"\n",
    "pathroi = \"\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ROI\"\n",
    "\n",
    "# funzione per creazione maschera\n",
    "def maskcroppingbox(images_array):\n",
    "    images_array_2 = np.argwhere(images_array)\n",
    "    \n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = images_array_2.min(axis=0), images_array_2.max(axis=0) + 1\n",
    "    return (zstart, ystart, xstart), (zstop, ystop, xstop)\n",
    "        \n",
    "def featureextraction(image_array, mask_array, patient_id):\n",
    "    # Ridimensionamento della ROI\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = maskcroppingbox(mask_array)\n",
    "    roi_images = image_array[zstart-1:zstop+1, ystart:ystop, xstart:xstop].transpose((2, 1, 0))\n",
    "    roi_images1 = zoom(roi_images, zoom=[224/roi_images.shape[0], 224/roi_images.shape[1], 1], order=3)\n",
    "    roi_images2 = np.array(roi_images1, dtype=float)\n",
    "\n",
    "    # Prepara tutte le slice come un batch\n",
    "    batch_slices = []\n",
    "    for slice_index in range(roi_images2.shape[2]):\n",
    "        slice_image = roi_images2[:, :, slice_index]\n",
    "        x = image.img_to_array(slice_image)\n",
    "        x = np.repeat(x, 3, axis=-1)  # Ripeti il canale se è un'immagine a singolo canale\n",
    "        batch_slices.append(x)\n",
    "\n",
    "    # Converti tutte le slice in un batch di input per ResNet\n",
    "    batch_slices = np.array(batch_slices)\n",
    "    batch_slices = preprocess_input(batch_slices)\n",
    "\n",
    "    # Estrazione feature map per tutto il batch\n",
    "    base_model_pool_features = model.predict(batch_slices)\n",
    "\n",
    "    # Inizializza lista per salvare tutte le features\n",
    "    all_features = []\n",
    "\n",
    "    # Estrai le feature map per ogni slice e salva con il numero del paziente e della slice\n",
    "    for slice_index in range(base_model_pool_features.shape[0]):\n",
    "        feature_map = base_model_pool_features[slice_index]\n",
    "\n",
    "        # Trasposizione e riduzione delle features\n",
    "        print(feature_map.shape)\n",
    "        feature_map = feature_map.transpose((2, 1, 0))\n",
    "        print(feature_map.shape)\n",
    "        features = np.max(feature_map, -1)\n",
    "        print(features.shape)\n",
    "        features = np.max(features, -1)\n",
    "        print(features.shape)\n",
    "\n",
    "        # Aggiungi le feature con il numero della slice e del paziente\n",
    "        feature_entry = {'Patient': patient_id, 'Slice': slice_index}\n",
    "        for ind_, f_ in enumerate(features):\n",
    "            feature_entry[f'Feature_{ind_}'] = f_\n",
    "\n",
    "        all_features.append(feature_entry)\n",
    "\n",
    "    return all_features\n",
    "\n",
    "\n",
    "all_feature_dicts = []\n",
    "\n",
    "for s in os.listdir(pathdicom):\n",
    "    print(s)\n",
    "    filename = os.path.join(pathdicom, s)\n",
    "\n",
    "    for t in os.listdir(filename):\n",
    "        pathdicomnew = os.path.join(pathdicom, s, t)\n",
    "        readdatadicom, header = nrrd.read(pathdicomnew, index_order='C')\n",
    "\n",
    "    pathroinew = os.path.join(pathroi, s)\n",
    "    for g in os.listdir(pathroinew):\n",
    "        troi = os.path.join(pathroi, s, g)\n",
    "        readdatanrrd, header2 = nrrd.read(troi, index_order='C')\n",
    "\n",
    "    # Estrai tutte le features per tutte le slice\n",
    "    patient_features = featureextraction(readdatadicom, readdatanrrd, patient_id=s)\n",
    "\n",
    "    # Aggiungi le feature di tutte le slice per questo paziente\n",
    "    all_feature_dicts.extend(patient_features)\n",
    "\n",
    "# Crea il DataFrame con le feature di tutte le slice e pazienti\n",
    "dataframe = pd.DataFrame(all_feature_dicts)\n",
    "\n",
    "# Salva il DataFrame in un file CSV\n",
    "dataframe.to_csv('C:\\\\Users\\\\bsbar\\\\Desktop\\\\RESNET50_ALL_SLICES_new.csv', index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice con indici corretti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: 100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
      "Processing patient: 101\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step\n",
      "Processing patient: 102\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step\n",
      "Processing patient: 103\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n",
      "Processing patient: 104\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n",
      "Processing patient: 105\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step\n",
      "Processing patient: 106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step\n",
      "Processing patient: 107\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step\n",
      "Processing patient: 108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "Processing patient: 109\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step\n",
      "Processing patient: 110\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
      "Processing patient: 111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "Processing patient: 112\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step\n",
      "Processing patient: 113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step\n",
      "Processing patient: 114\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step\n",
      "Processing patient: 115\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n",
      "Processing patient: 116\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276ms/step\n",
      "Processing patient: 117\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n",
      "Processing patient: 118\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step\n",
      "Processing patient: 119\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step\n",
      "Processing patient: 12\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step\n",
      "Processing patient: 120\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n",
      "Processing patient: 123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
      "Processing patient: 124\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step\n",
      "Processing patient: 126\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step\n",
      "Processing patient: 127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "Processing patient: 128\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step\n",
      "Processing patient: 129\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step\n",
      "Processing patient: 133\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step\n",
      "Processing patient: 135\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step\n",
      "Processing patient: 136\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step\n",
      "Processing patient: 137\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step\n",
      "Processing patient: 138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
      "Processing patient: 139\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658ms/step\n",
      "Processing patient: 141\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step\n",
      "Processing patient: 142\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n",
      "Processing patient: 144\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
      "Processing patient: 146\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step\n",
      "Processing patient: 147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "Processing patient: 149\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
      "Processing patient: 15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step\n",
      "Processing patient: 150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step\n",
      "Processing patient: 153\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "Processing patient: 155\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 535ms/step\n",
      "Processing patient: 158\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step\n",
      "Processing patient: 159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741ms/step\n",
      "Processing patient: 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
      "Processing patient: 161\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 376ms/step\n",
      "Processing patient: 163\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
      "Processing patient: 166\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
      "Processing patient: 168\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step\n",
      "Processing patient: 169\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step\n",
      "Processing patient: 17\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
      "Processing patient: 170\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
      "Processing patient: 171\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 443ms/step\n",
      "Processing patient: 175\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n",
      "Processing patient: 176\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step\n",
      "Processing patient: 178\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
      "Processing patient: 182\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step\n",
      "Processing patient: 183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803ms/step\n",
      "Processing patient: 188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821ms/step\n",
      "Processing patient: 189\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
      "Processing patient: 19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920ms/step\n",
      "Processing patient: 190\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671ms/step\n",
      "Processing patient: 193\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step\n",
      "Processing patient: 197\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731ms/step\n",
      "Processing patient: 199\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 832ms/step\n",
      "Processing patient: 200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707ms/step\n",
      "Processing patient: 205\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738ms/step\n",
      "Processing patient: 22\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step\n",
      "Processing patient: 23\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785ms/step\n",
      "Processing patient: 24\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744ms/step\n",
      "Processing patient: 25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step\n",
      "Processing patient: 26\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step\n",
      "Processing patient: 27\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 935ms/step\n",
      "Processing patient: 29\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
      "Processing patient: 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step\n",
      "Processing patient: 31\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948ms/step\n",
      "Processing patient: 33\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963ms/step\n",
      "Processing patient: 35\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968ms/step\n",
      "Processing patient: 36\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step\n",
      "Processing patient: 38\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893ms/step\n",
      "Processing patient: 39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step\n",
      "Processing patient: 40\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 479ms/step\n",
      "Processing patient: 41\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 773ms/step\n",
      "Processing patient: 42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808ms/step\n",
      "Processing patient: 43\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
      "Processing patient: 44\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 46\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754ms/step\n",
      "Processing patient: 47\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810ms/step\n",
      "Processing patient: 48\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 471ms/step\n",
      "Processing patient: 5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
      "Processing patient: 50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step\n",
      "Processing patient: 52\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707ms/step\n",
      "Processing patient: 53\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step\n",
      "Processing patient: 54\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735ms/step\n",
      "Processing patient: 56\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step\n",
      "Processing patient: 57\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 764ms/step\n",
      "Processing patient: 58\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635ms/step\n",
      "Processing patient: 59\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step\n",
      "Processing patient: 60\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934ms/step\n",
      "Processing patient: 61\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701ms/step\n",
      "Processing patient: 62\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 440ms/step\n",
      "Processing patient: 64\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step\n",
      "Processing patient: 65\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step\n",
      "Processing patient: 68\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 880ms/step\n",
      "Processing patient: 69\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "Processing patient: 70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 597ms/step\n",
      "Processing patient: 71\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 74\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 75\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step\n",
      "Processing patient: 76\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step\n",
      "Processing patient: 78\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step\n",
      "Processing patient: 79\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 81\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 82\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "Processing patient: 84\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 934ms/step\n",
      "Processing patient: 85\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step\n",
      "Processing patient: 86\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 87\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n",
      "Processing patient: 88\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 562ms/step\n",
      "Processing patient: 89\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step\n",
      "Processing patient: 90\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step\n",
      "Processing patient: 91\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 857ms/step\n",
      "Processing patient: 92\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 94\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 95\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Processing patient: 96\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step\n",
      "Processing patient: 98\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 626ms/step\n",
      "CSV con gli indici 3D salvato con successo.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "pathdicom = \"\\\\Users\\\\bsbar\\\\Desktop\\\\pazienti_nrrd\"\n",
    "pathroi = \"\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ROI\"\n",
    "\n",
    "# funzione per creazione maschera\n",
    "def maskcroppingbox(images_array):\n",
    "    images_array_2 = np.argwhere(images_array)\n",
    "    \n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = images_array_2.min(axis=0), images_array_2.max(axis=0) + 1\n",
    "    return (zstart, ystart, xstart), (zstop, ystop, xstop)\n",
    "        \n",
    "def featureextraction(image_array, mask_array, patient_id):\n",
    "    # Ridimensionamento della ROI\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = maskcroppingbox(mask_array)\n",
    "    # Qui stiamo lavorando con l'array originale, quindi manteniamo gli indici originali delle slice\n",
    "    original_slice_indices = np.arange(zstart, zstop)  # Manteniamo gli indici delle slice originali\n",
    "\n",
    "    # Tagliare il volume solo sulle slice che contengono la placca\n",
    "    roi_images = image_array[zstart:zstop, ystart:ystop, xstart:xstop].transpose((2, 1, 0))\n",
    "    roi_images1 = zoom(roi_images, zoom=[224/roi_images.shape[0], 224/roi_images.shape[1], 1], order=3)\n",
    "    roi_images2 = np.array(roi_images1, dtype=float)\n",
    "\n",
    "    # Prepara tutte le slice come un batch\n",
    "    batch_slices = []\n",
    "    for slice_index in range(roi_images2.shape[2]):\n",
    "        slice_image = roi_images2[:, :, slice_index]\n",
    "        x = image.img_to_array(slice_image)\n",
    "        x = np.repeat(x, 3, axis=-1)  # Ripeti il canale se è un'immagine a singolo canale\n",
    "        batch_slices.append(x)\n",
    "\n",
    "    # Converti tutte le slice in un batch di input per ResNet\n",
    "    batch_slices = np.array(batch_slices)\n",
    "    batch_slices = preprocess_input(batch_slices)\n",
    "\n",
    "    # Estrazione feature map per tutto il batch\n",
    "    base_model_pool_features = model.predict(batch_slices)\n",
    "\n",
    "    # Inizializza lista per salvare tutte le features\n",
    "    all_features = []\n",
    "\n",
    "    placca_indices_3d = list(range(zstart, zstop + 1))\n",
    "\n",
    "\n",
    "    # Usa solo le slice corrispondenti agli indici originali\n",
    "    for i in range(base_model_pool_features.shape[0]):\n",
    "        feature_map = base_model_pool_features[i]\n",
    "\n",
    "        # Trasposizione e riduzione delle features\n",
    "        feature_map = feature_map.transpose((2, 1, 0))\n",
    "        features = np.max(feature_map, -1)\n",
    "        features = np.max(features, -1)\n",
    "\n",
    "        # Associa l'indice reale della slice (non sequenziale) dal volume originale\n",
    "        feature_entry = {'Patient': patient_id, 'Slice': original_slice_indices[i]}  # Usa l'indice reale della slice\n",
    "        for ind_, f_ in enumerate(features):\n",
    "            feature_entry[f'Feature_{ind_}'] = f_\n",
    "\n",
    "        all_features.append(feature_entry)\n",
    "\n",
    "    return all_features, placca_indices_3d\n",
    "\n",
    "\n",
    "all_feature_dicts = []\n",
    "\n",
    "for s in os.listdir(pathdicom):\n",
    "    print(f\"Processing patient: {s}\")\n",
    "    filename = os.path.join(pathdicom, s)\n",
    "\n",
    "    for t in os.listdir(filename):\n",
    "        pathdicomnew = os.path.join(pathdicom, s, t)\n",
    "        readdatadicom, header = nrrd.read(pathdicomnew, index_order='C')\n",
    "\n",
    "    pathroinew = os.path.join(pathroi, s)\n",
    "    for g in os.listdir(pathroinew):\n",
    "        troi = os.path.join(pathroi, s, g)\n",
    "        readdatanrrd, header2 = nrrd.read(troi, index_order='C')\n",
    "\n",
    "    # Estrai tutte le features e gli indici delle slice in 3D\n",
    "    patient_features, placca_indices_3d = featureextraction(readdatadicom, readdatanrrd, patient_id=s)\n",
    "\n",
    "    # Aggiungi gli indici 3D alle features\n",
    "    for feature_dict, slice_index_3d in zip(patient_features, placca_indices_3d):\n",
    "        feature_dict['3D_Slice_Index'] = slice_index_3d  # Aggiungi l'indice originale 3D della slice\n",
    "\n",
    "    # Aggiungi le feature di tutte le slice per questo paziente\n",
    "    all_feature_dicts.extend(patient_features)\n",
    "\n",
    "# Crea il DataFrame con le feature di tutte le slice e pazienti\n",
    "dataframe = pd.DataFrame(all_feature_dicts)\n",
    "\n",
    "# Salva il DataFrame in un file CSV\n",
    "dataframe.to_csv('C:\\\\Users\\\\bsbar\\\\Desktop\\\\INCEPTION_ALL_SLICES_with_3D_indices.csv', index=False)\n",
    "\n",
    "print(\"CSV con gli indici 3D salvato con successo.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\bsbar/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:07<00:00, 4.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "101\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n",
      "102\n",
      "Original depth: 54\n",
      "Features shape: (1024, 54, 7, 7)\n",
      "103\n",
      "Original depth: 46\n",
      "Features shape: (1024, 46, 7, 7)\n",
      "104\n",
      "Original depth: 45\n",
      "Features shape: (1024, 45, 7, 7)\n",
      "105\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "106\n",
      "Original depth: 30\n",
      "Features shape: (1024, 30, 7, 7)\n",
      "107\n",
      "Original depth: 44\n",
      "Features shape: (1024, 44, 7, 7)\n",
      "108\n",
      "Original depth: 27\n",
      "Features shape: (1024, 27, 7, 7)\n",
      "109\n",
      "Original depth: 41\n",
      "Features shape: (1024, 41, 7, 7)\n",
      "110\n",
      "Original depth: 49\n",
      "Features shape: (1024, 49, 7, 7)\n",
      "111\n",
      "Original depth: 26\n",
      "Features shape: (1024, 26, 7, 7)\n",
      "112\n",
      "Original depth: 46\n",
      "Features shape: (1024, 46, 7, 7)\n",
      "113\n",
      "Original depth: 27\n",
      "Features shape: (1024, 27, 7, 7)\n",
      "114\n",
      "Original depth: 37\n",
      "Features shape: (1024, 37, 7, 7)\n",
      "115\n",
      "Original depth: 44\n",
      "Features shape: (1024, 44, 7, 7)\n",
      "116\n",
      "Original depth: 41\n",
      "Features shape: (1024, 41, 7, 7)\n",
      "117\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "118\n",
      "Original depth: 46\n",
      "Features shape: (1024, 46, 7, 7)\n",
      "119\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "12\n",
      "Original depth: 36\n",
      "Features shape: (1024, 36, 7, 7)\n",
      "120\n",
      "Original depth: 55\n",
      "Features shape: (1024, 55, 7, 7)\n",
      "123\n",
      "Original depth: 28\n",
      "Features shape: (1024, 28, 7, 7)\n",
      "124\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "126\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n",
      "127\n",
      "Original depth: 24\n",
      "Features shape: (1024, 24, 7, 7)\n",
      "128\n",
      "Original depth: 41\n",
      "Features shape: (1024, 41, 7, 7)\n",
      "129\n",
      "Original depth: 44\n",
      "Features shape: (1024, 44, 7, 7)\n",
      "133\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "135\n",
      "Original depth: 45\n",
      "Features shape: (1024, 45, 7, 7)\n",
      "136\n",
      "Original depth: 44\n",
      "Features shape: (1024, 44, 7, 7)\n",
      "137\n",
      "Original depth: 66\n",
      "Features shape: (1024, 66, 7, 7)\n",
      "138\n",
      "Original depth: 25\n",
      "Features shape: (1024, 25, 7, 7)\n",
      "139\n",
      "Original depth: 32\n",
      "Features shape: (1024, 32, 7, 7)\n",
      "141\n",
      "Original depth: 36\n",
      "Features shape: (1024, 36, 7, 7)\n",
      "142\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n",
      "144\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "146\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "147\n",
      "Original depth: 22\n",
      "Features shape: (1024, 22, 7, 7)\n",
      "149\n",
      "Original depth: 34\n",
      "Features shape: (1024, 34, 7, 7)\n",
      "15\n",
      "Original depth: 49\n",
      "Features shape: (1024, 49, 7, 7)\n",
      "150\n",
      "Original depth: 43\n",
      "Features shape: (1024, 43, 7, 7)\n",
      "153\n",
      "Original depth: 51\n",
      "Features shape: (1024, 51, 7, 7)\n",
      "155\n",
      "Original depth: 74\n",
      "Features shape: (1024, 74, 7, 7)\n",
      "158\n",
      "Original depth: 35\n",
      "Features shape: (1024, 35, 7, 7)\n",
      "159\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "16\n",
      "Original depth: 22\n",
      "Features shape: (1024, 22, 7, 7)\n",
      "161\n",
      "Original depth: 43\n",
      "Features shape: (1024, 43, 7, 7)\n",
      "163\n",
      "Original depth: 52\n",
      "Features shape: (1024, 52, 7, 7)\n",
      "166\n",
      "Original depth: 50\n",
      "Features shape: (1024, 50, 7, 7)\n",
      "168\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n",
      "169\n",
      "Original depth: 39\n",
      "Features shape: (1024, 39, 7, 7)\n",
      "17\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "170\n",
      "Original depth: 54\n",
      "Features shape: (1024, 54, 7, 7)\n",
      "171\n",
      "Original depth: 65\n",
      "Features shape: (1024, 65, 7, 7)\n",
      "175\n",
      "Original depth: 52\n",
      "Features shape: (1024, 52, 7, 7)\n",
      "176\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "178\n",
      "Original depth: 43\n",
      "Features shape: (1024, 43, 7, 7)\n",
      "182\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "183\n",
      "Original depth: 29\n",
      "Features shape: (1024, 29, 7, 7)\n",
      "188\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "189\n",
      "Original depth: 45\n",
      "Features shape: (1024, 45, 7, 7)\n",
      "19\n",
      "Original depth: 29\n",
      "Features shape: (1024, 29, 7, 7)\n",
      "190\n",
      "Original depth: 51\n",
      "Features shape: (1024, 51, 7, 7)\n",
      "193\n",
      "Original depth: 37\n",
      "Features shape: (1024, 37, 7, 7)\n",
      "197\n",
      "Original depth: 55\n",
      "Features shape: (1024, 55, 7, 7)\n",
      "199\n",
      "Original depth: 54\n",
      "Features shape: (1024, 54, 7, 7)\n",
      "200\n",
      "Original depth: 51\n",
      "Features shape: (1024, 51, 7, 7)\n",
      "205\n",
      "Original depth: 51\n",
      "Features shape: (1024, 51, 7, 7)\n",
      "22\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n",
      "23\n",
      "Original depth: 57\n",
      "Features shape: (1024, 57, 7, 7)\n",
      "24\n",
      "Original depth: 51\n",
      "Features shape: (1024, 51, 7, 7)\n",
      "25\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "26\n",
      "Original depth: 34\n",
      "Features shape: (1024, 34, 7, 7)\n",
      "27\n",
      "Original depth: 60\n",
      "Features shape: (1024, 60, 7, 7)\n",
      "29\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "30\n",
      "Original depth: 26\n",
      "Features shape: (1024, 26, 7, 7)\n",
      "31\n",
      "Original depth: 29\n",
      "Features shape: (1024, 29, 7, 7)\n",
      "33\n",
      "Original depth: 63\n",
      "Features shape: (1024, 63, 7, 7)\n",
      "35\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "36\n",
      "Original depth: 34\n",
      "Features shape: (1024, 34, 7, 7)\n",
      "38\n",
      "Original depth: 26\n",
      "Features shape: (1024, 26, 7, 7)\n",
      "39\n",
      "Original depth: 26\n",
      "Features shape: (1024, 26, 7, 7)\n",
      "40\n",
      "Original depth: 41\n",
      "Features shape: (1024, 41, 7, 7)\n",
      "41\n",
      "Original depth: 50\n",
      "Features shape: (1024, 50, 7, 7)\n",
      "42\n",
      "Original depth: 18\n",
      "Features shape: (1024, 18, 7, 7)\n",
      "43\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "44\n",
      "Original depth: 30\n",
      "Features shape: (1024, 30, 7, 7)\n",
      "46\n",
      "Original depth: 49\n",
      "Features shape: (1024, 49, 7, 7)\n",
      "47\n",
      "Original depth: 50\n",
      "Features shape: (1024, 50, 7, 7)\n",
      "48\n",
      "Original depth: 41\n",
      "Features shape: (1024, 41, 7, 7)\n",
      "5\n",
      "Original depth: 39\n",
      "Features shape: (1024, 39, 7, 7)\n",
      "50\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "52\n",
      "Original depth: 47\n",
      "Features shape: (1024, 47, 7, 7)\n",
      "53\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "54\n",
      "Original depth: 48\n",
      "Features shape: (1024, 48, 7, 7)\n",
      "56\n",
      "Original depth: 39\n",
      "Features shape: (1024, 39, 7, 7)\n",
      "57\n",
      "Original depth: 49\n",
      "Features shape: (1024, 49, 7, 7)\n",
      "58\n",
      "Original depth: 45\n",
      "Features shape: (1024, 45, 7, 7)\n",
      "59\n",
      "Original depth: 37\n",
      "Features shape: (1024, 37, 7, 7)\n",
      "60\n",
      "Original depth: 24\n",
      "Features shape: (1024, 24, 7, 7)\n",
      "61\n",
      "Original depth: 47\n",
      "Features shape: (1024, 47, 7, 7)\n",
      "62\n",
      "Original depth: 39\n",
      "Features shape: (1024, 39, 7, 7)\n",
      "64\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "65\n",
      "Original depth: 20\n",
      "Features shape: (1024, 20, 7, 7)\n",
      "68\n",
      "Original depth: 52\n",
      "Features shape: (1024, 52, 7, 7)\n",
      "69\n",
      "Original depth: 33\n",
      "Features shape: (1024, 33, 7, 7)\n",
      "70\n",
      "Original depth: 43\n",
      "Features shape: (1024, 43, 7, 7)\n",
      "71\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "74\n",
      "Original depth: 30\n",
      "Features shape: (1024, 30, 7, 7)\n",
      "75\n",
      "Original depth: 39\n",
      "Features shape: (1024, 39, 7, 7)\n",
      "76\n",
      "Original depth: 36\n",
      "Features shape: (1024, 36, 7, 7)\n",
      "78\n",
      "Original depth: 38\n",
      "Features shape: (1024, 38, 7, 7)\n",
      "79\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "81\n",
      "Original depth: 29\n",
      "Features shape: (1024, 29, 7, 7)\n",
      "82\n",
      "Original depth: 57\n",
      "Features shape: (1024, 57, 7, 7)\n",
      "84\n",
      "Original depth: 74\n",
      "Features shape: (1024, 74, 7, 7)\n",
      "85\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "86\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "87\n",
      "Original depth: 113\n",
      "Features shape: (1024, 113, 7, 7)\n",
      "88\n",
      "Original depth: 40\n",
      "Features shape: (1024, 40, 7, 7)\n",
      "89\n",
      "Original depth: 36\n",
      "Features shape: (1024, 36, 7, 7)\n",
      "90\n",
      "Original depth: 34\n",
      "Features shape: (1024, 34, 7, 7)\n",
      "91\n",
      "Original depth: 48\n",
      "Features shape: (1024, 48, 7, 7)\n",
      "92\n",
      "Original depth: 31\n",
      "Features shape: (1024, 31, 7, 7)\n",
      "94\n",
      "Original depth: 26\n",
      "Features shape: (1024, 26, 7, 7)\n",
      "95\n",
      "Original depth: 24\n",
      "Features shape: (1024, 24, 7, 7)\n",
      "96\n",
      "Original depth: 34\n",
      "Features shape: (1024, 34, 7, 7)\n",
      "98\n",
      "Original depth: 42\n",
      "Features shape: (1024, 42, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nrrd\n",
    "from torchvision_3d.models import ResNet3D\n",
    "from torchvision_3d.models import VGG3D\n",
    "from torchvision_3d.models import DenseNet3D\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Carica la ResNet50 3D pretrainata\n",
    "model = DenseNet3D(type='densenet121', pretrained=True)\n",
    "model = model.eval()  # Modalità inferenza\n",
    "\n",
    "# Funzione per il cropping della maschera 3D\n",
    "def maskcroppingbox(images_array):\n",
    "    images_array_2 = np.argwhere(images_array)\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = images_array_2.min(axis=0), images_array_2.max(axis=0) + 1\n",
    "    return (zstart, ystart, xstart), (zstop, ystop, xstop)\n",
    "\n",
    "# Funzione per l'estrazione delle feature da un volume 3D\n",
    "def featureextraction(image_array, mask_array, patient_id):\n",
    "    # Estrarre solo le slice che contengono la maschera\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = maskcroppingbox(mask_array)\n",
    "    roi_images = image_array[zstart:zstop, ystart:ystop, xstart:xstop]  # Volume 3D\n",
    "    \n",
    "    # Ridimensionare il volume alla dimensione richiesta (224x224xD, dove D varia)\n",
    "    depth = roi_images.shape[0]  # La profondità originale\n",
    "    print(\"Original depth:\", depth)\n",
    "\n",
    "    # Ridimensiona altezza e larghezza a 224, mantieni invariata la profondità\n",
    "    roi_images_resized = zoom(roi_images, zoom=[1, 224/roi_images.shape[1], 224/roi_images.shape[2]], order=3)\n",
    "    #print(\"Shape after resize:\", roi_images_resized.shape)\n",
    "\n",
    "    roi_images_resized = np.expand_dims(roi_images_resized, axis=0)  # Aggiungi dimensione batch\n",
    "    roi_images_resized = np.repeat(roi_images_resized, 3, axis=0)  # Da (1, D, H, W) a (3, D, H, W)\n",
    "\n",
    "    # Converti il volume 3D in tensor\n",
    "    volume_tensor = torch.tensor(roi_images_resized, dtype=torch.float32)\n",
    "    volume_tensor = volume_tensor.unsqueeze(0)  # (1, 1, D, H, W) - batch size 1, canale 1\n",
    "\n",
    "    #print(volume_tensor.shape)\n",
    "\n",
    "    # Passa il volume 3D attraverso la rete pre-addestrata\n",
    "    with torch.no_grad():\n",
    "        features = model(volume_tensor)\n",
    "\n",
    "    #print(f\"Features shape: {features.shape}\")\n",
    "    # Estrai le feature map finali (saranno 2048 features per ResNet50)\n",
    "    features = features.squeeze().numpy()\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    features = np.max(features, axis=3)  # Riduci lungo la profondità\n",
    "    features = np.max(features, axis=2)  # Riduci lungo una dimensione spaziale\n",
    "    features = np.max(features, axis=1)  # Riduci lungo l'altra dimensione spaziale\n",
    "    #print(f\"Features shape: {features.shape}\")\n",
    "\n",
    "    # Aggiungi le feature con il numero del paziente e la profondità\n",
    "    feature_entry = {'Patient': patient_id}\n",
    "    for ind_, f_ in enumerate(features):\n",
    "        feature_entry[f'Feature_{ind_}'] = f_\n",
    "\n",
    "    return feature_entry\n",
    "\n",
    "# Percorsi ai dati\n",
    "pathdicom = \"\\\\Users\\\\bsbar\\\\Desktop\\\\pazienti_nrrd\"\n",
    "pathroi = \"\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ROI\"\n",
    "\n",
    "# Inizializza lista per salvare tutte le feature\n",
    "all_feature_dicts = []\n",
    "\n",
    "# Ciclo sui pazienti\n",
    "for s in os.listdir(pathdicom):\n",
    "    print(s)\n",
    "    filename = os.path.join(pathdicom, s)\n",
    "\n",
    "    for t in os.listdir(filename):\n",
    "        pathdicomnew = os.path.join(pathdicom, s, t)\n",
    "        readdatadicom, header = nrrd.read(pathdicomnew, index_order='C')\n",
    "\n",
    "    pathroinew = os.path.join(pathroi, s)\n",
    "    for g in os.listdir(pathroinew):\n",
    "        troi = os.path.join(pathroi, s, g)\n",
    "        readdatanrrd, header2 = nrrd.read(troi, index_order='C')\n",
    "\n",
    "    # Estrai tutte le features per il volume 3D\n",
    "    patient_features = featureextraction(readdatadicom, readdatanrrd, patient_id=s)\n",
    "\n",
    "    # Aggiungi le feature di tutte le slice per questo paziente\n",
    "    all_feature_dicts.append(patient_features)\n",
    "\n",
    "# Crea il DataFrame con le feature di tutte le slice e pazienti\n",
    "dataframe = pd.DataFrame(all_feature_dicts)\n",
    "\n",
    "# Salva il DataFrame in un file CSV\n",
    "dataframe.to_csv('C:\\\\Users\\\\bsbar\\\\Desktop\\\\DENSENET121_3D.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
